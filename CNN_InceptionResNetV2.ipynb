{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN - InceptionResNetV2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lcroffi/CNN/blob/master/CNN_InceptionResNetV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9gzffzqjRV9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e1a7aaa-ed9a-4eeb-a664-e5f9992fbb3e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txSM5NfekPdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_width, img_height = 299, 299"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t7ds29tkViC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "d5f3b71e-5412-42ec-f571-79400dbc5714"
      },
      "source": [
        "# importa o modelo InceptionResNetV2 e descarta a Ãºltima camada do classifier.\n",
        "base_model=InceptionResNetV2(weights='imagenet',include_top=False, input_shape=(img_width, img_height, 3))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0719 18:54:03.482046 140624009312128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0719 18:54:03.525911 140624009312128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0719 18:54:03.535020 140624009312128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0719 18:54:03.564234 140624009312128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0719 18:54:03.565102 140624009312128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0719 18:54:06.419719 140624009312128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0719 18:54:06.638212 140624009312128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0719 18:54:07.300678 140624009312128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219062272/219055592 [==============================] - 8s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHQFj6jOkq1M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e89a09bf-79c4-4c79-a115-5786adc4df20"
      },
      "source": [
        "for i, layer in enumerate(base_model.layers):\n",
        "   print(i, layer.name)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_1\n",
            "1 conv2d_1\n",
            "2 batch_normalization_1\n",
            "3 activation_1\n",
            "4 conv2d_2\n",
            "5 batch_normalization_2\n",
            "6 activation_2\n",
            "7 conv2d_3\n",
            "8 batch_normalization_3\n",
            "9 activation_3\n",
            "10 max_pooling2d_1\n",
            "11 conv2d_4\n",
            "12 batch_normalization_4\n",
            "13 activation_4\n",
            "14 conv2d_5\n",
            "15 batch_normalization_5\n",
            "16 activation_5\n",
            "17 max_pooling2d_2\n",
            "18 conv2d_9\n",
            "19 batch_normalization_9\n",
            "20 activation_9\n",
            "21 conv2d_7\n",
            "22 conv2d_10\n",
            "23 batch_normalization_7\n",
            "24 batch_normalization_10\n",
            "25 activation_7\n",
            "26 activation_10\n",
            "27 average_pooling2d_1\n",
            "28 conv2d_6\n",
            "29 conv2d_8\n",
            "30 conv2d_11\n",
            "31 conv2d_12\n",
            "32 batch_normalization_6\n",
            "33 batch_normalization_8\n",
            "34 batch_normalization_11\n",
            "35 batch_normalization_12\n",
            "36 activation_6\n",
            "37 activation_8\n",
            "38 activation_11\n",
            "39 activation_12\n",
            "40 mixed_5b\n",
            "41 conv2d_16\n",
            "42 batch_normalization_16\n",
            "43 activation_16\n",
            "44 conv2d_14\n",
            "45 conv2d_17\n",
            "46 batch_normalization_14\n",
            "47 batch_normalization_17\n",
            "48 activation_14\n",
            "49 activation_17\n",
            "50 conv2d_13\n",
            "51 conv2d_15\n",
            "52 conv2d_18\n",
            "53 batch_normalization_13\n",
            "54 batch_normalization_15\n",
            "55 batch_normalization_18\n",
            "56 activation_13\n",
            "57 activation_15\n",
            "58 activation_18\n",
            "59 block35_1_mixed\n",
            "60 block35_1_conv\n",
            "61 block35_1\n",
            "62 block35_1_ac\n",
            "63 conv2d_22\n",
            "64 batch_normalization_22\n",
            "65 activation_22\n",
            "66 conv2d_20\n",
            "67 conv2d_23\n",
            "68 batch_normalization_20\n",
            "69 batch_normalization_23\n",
            "70 activation_20\n",
            "71 activation_23\n",
            "72 conv2d_19\n",
            "73 conv2d_21\n",
            "74 conv2d_24\n",
            "75 batch_normalization_19\n",
            "76 batch_normalization_21\n",
            "77 batch_normalization_24\n",
            "78 activation_19\n",
            "79 activation_21\n",
            "80 activation_24\n",
            "81 block35_2_mixed\n",
            "82 block35_2_conv\n",
            "83 block35_2\n",
            "84 block35_2_ac\n",
            "85 conv2d_28\n",
            "86 batch_normalization_28\n",
            "87 activation_28\n",
            "88 conv2d_26\n",
            "89 conv2d_29\n",
            "90 batch_normalization_26\n",
            "91 batch_normalization_29\n",
            "92 activation_26\n",
            "93 activation_29\n",
            "94 conv2d_25\n",
            "95 conv2d_27\n",
            "96 conv2d_30\n",
            "97 batch_normalization_25\n",
            "98 batch_normalization_27\n",
            "99 batch_normalization_30\n",
            "100 activation_25\n",
            "101 activation_27\n",
            "102 activation_30\n",
            "103 block35_3_mixed\n",
            "104 block35_3_conv\n",
            "105 block35_3\n",
            "106 block35_3_ac\n",
            "107 conv2d_34\n",
            "108 batch_normalization_34\n",
            "109 activation_34\n",
            "110 conv2d_32\n",
            "111 conv2d_35\n",
            "112 batch_normalization_32\n",
            "113 batch_normalization_35\n",
            "114 activation_32\n",
            "115 activation_35\n",
            "116 conv2d_31\n",
            "117 conv2d_33\n",
            "118 conv2d_36\n",
            "119 batch_normalization_31\n",
            "120 batch_normalization_33\n",
            "121 batch_normalization_36\n",
            "122 activation_31\n",
            "123 activation_33\n",
            "124 activation_36\n",
            "125 block35_4_mixed\n",
            "126 block35_4_conv\n",
            "127 block35_4\n",
            "128 block35_4_ac\n",
            "129 conv2d_40\n",
            "130 batch_normalization_40\n",
            "131 activation_40\n",
            "132 conv2d_38\n",
            "133 conv2d_41\n",
            "134 batch_normalization_38\n",
            "135 batch_normalization_41\n",
            "136 activation_38\n",
            "137 activation_41\n",
            "138 conv2d_37\n",
            "139 conv2d_39\n",
            "140 conv2d_42\n",
            "141 batch_normalization_37\n",
            "142 batch_normalization_39\n",
            "143 batch_normalization_42\n",
            "144 activation_37\n",
            "145 activation_39\n",
            "146 activation_42\n",
            "147 block35_5_mixed\n",
            "148 block35_5_conv\n",
            "149 block35_5\n",
            "150 block35_5_ac\n",
            "151 conv2d_46\n",
            "152 batch_normalization_46\n",
            "153 activation_46\n",
            "154 conv2d_44\n",
            "155 conv2d_47\n",
            "156 batch_normalization_44\n",
            "157 batch_normalization_47\n",
            "158 activation_44\n",
            "159 activation_47\n",
            "160 conv2d_43\n",
            "161 conv2d_45\n",
            "162 conv2d_48\n",
            "163 batch_normalization_43\n",
            "164 batch_normalization_45\n",
            "165 batch_normalization_48\n",
            "166 activation_43\n",
            "167 activation_45\n",
            "168 activation_48\n",
            "169 block35_6_mixed\n",
            "170 block35_6_conv\n",
            "171 block35_6\n",
            "172 block35_6_ac\n",
            "173 conv2d_52\n",
            "174 batch_normalization_52\n",
            "175 activation_52\n",
            "176 conv2d_50\n",
            "177 conv2d_53\n",
            "178 batch_normalization_50\n",
            "179 batch_normalization_53\n",
            "180 activation_50\n",
            "181 activation_53\n",
            "182 conv2d_49\n",
            "183 conv2d_51\n",
            "184 conv2d_54\n",
            "185 batch_normalization_49\n",
            "186 batch_normalization_51\n",
            "187 batch_normalization_54\n",
            "188 activation_49\n",
            "189 activation_51\n",
            "190 activation_54\n",
            "191 block35_7_mixed\n",
            "192 block35_7_conv\n",
            "193 block35_7\n",
            "194 block35_7_ac\n",
            "195 conv2d_58\n",
            "196 batch_normalization_58\n",
            "197 activation_58\n",
            "198 conv2d_56\n",
            "199 conv2d_59\n",
            "200 batch_normalization_56\n",
            "201 batch_normalization_59\n",
            "202 activation_56\n",
            "203 activation_59\n",
            "204 conv2d_55\n",
            "205 conv2d_57\n",
            "206 conv2d_60\n",
            "207 batch_normalization_55\n",
            "208 batch_normalization_57\n",
            "209 batch_normalization_60\n",
            "210 activation_55\n",
            "211 activation_57\n",
            "212 activation_60\n",
            "213 block35_8_mixed\n",
            "214 block35_8_conv\n",
            "215 block35_8\n",
            "216 block35_8_ac\n",
            "217 conv2d_64\n",
            "218 batch_normalization_64\n",
            "219 activation_64\n",
            "220 conv2d_62\n",
            "221 conv2d_65\n",
            "222 batch_normalization_62\n",
            "223 batch_normalization_65\n",
            "224 activation_62\n",
            "225 activation_65\n",
            "226 conv2d_61\n",
            "227 conv2d_63\n",
            "228 conv2d_66\n",
            "229 batch_normalization_61\n",
            "230 batch_normalization_63\n",
            "231 batch_normalization_66\n",
            "232 activation_61\n",
            "233 activation_63\n",
            "234 activation_66\n",
            "235 block35_9_mixed\n",
            "236 block35_9_conv\n",
            "237 block35_9\n",
            "238 block35_9_ac\n",
            "239 conv2d_70\n",
            "240 batch_normalization_70\n",
            "241 activation_70\n",
            "242 conv2d_68\n",
            "243 conv2d_71\n",
            "244 batch_normalization_68\n",
            "245 batch_normalization_71\n",
            "246 activation_68\n",
            "247 activation_71\n",
            "248 conv2d_67\n",
            "249 conv2d_69\n",
            "250 conv2d_72\n",
            "251 batch_normalization_67\n",
            "252 batch_normalization_69\n",
            "253 batch_normalization_72\n",
            "254 activation_67\n",
            "255 activation_69\n",
            "256 activation_72\n",
            "257 block35_10_mixed\n",
            "258 block35_10_conv\n",
            "259 block35_10\n",
            "260 block35_10_ac\n",
            "261 conv2d_74\n",
            "262 batch_normalization_74\n",
            "263 activation_74\n",
            "264 conv2d_75\n",
            "265 batch_normalization_75\n",
            "266 activation_75\n",
            "267 conv2d_73\n",
            "268 conv2d_76\n",
            "269 batch_normalization_73\n",
            "270 batch_normalization_76\n",
            "271 activation_73\n",
            "272 activation_76\n",
            "273 max_pooling2d_3\n",
            "274 mixed_6a\n",
            "275 conv2d_78\n",
            "276 batch_normalization_78\n",
            "277 activation_78\n",
            "278 conv2d_79\n",
            "279 batch_normalization_79\n",
            "280 activation_79\n",
            "281 conv2d_77\n",
            "282 conv2d_80\n",
            "283 batch_normalization_77\n",
            "284 batch_normalization_80\n",
            "285 activation_77\n",
            "286 activation_80\n",
            "287 block17_1_mixed\n",
            "288 block17_1_conv\n",
            "289 block17_1\n",
            "290 block17_1_ac\n",
            "291 conv2d_82\n",
            "292 batch_normalization_82\n",
            "293 activation_82\n",
            "294 conv2d_83\n",
            "295 batch_normalization_83\n",
            "296 activation_83\n",
            "297 conv2d_81\n",
            "298 conv2d_84\n",
            "299 batch_normalization_81\n",
            "300 batch_normalization_84\n",
            "301 activation_81\n",
            "302 activation_84\n",
            "303 block17_2_mixed\n",
            "304 block17_2_conv\n",
            "305 block17_2\n",
            "306 block17_2_ac\n",
            "307 conv2d_86\n",
            "308 batch_normalization_86\n",
            "309 activation_86\n",
            "310 conv2d_87\n",
            "311 batch_normalization_87\n",
            "312 activation_87\n",
            "313 conv2d_85\n",
            "314 conv2d_88\n",
            "315 batch_normalization_85\n",
            "316 batch_normalization_88\n",
            "317 activation_85\n",
            "318 activation_88\n",
            "319 block17_3_mixed\n",
            "320 block17_3_conv\n",
            "321 block17_3\n",
            "322 block17_3_ac\n",
            "323 conv2d_90\n",
            "324 batch_normalization_90\n",
            "325 activation_90\n",
            "326 conv2d_91\n",
            "327 batch_normalization_91\n",
            "328 activation_91\n",
            "329 conv2d_89\n",
            "330 conv2d_92\n",
            "331 batch_normalization_89\n",
            "332 batch_normalization_92\n",
            "333 activation_89\n",
            "334 activation_92\n",
            "335 block17_4_mixed\n",
            "336 block17_4_conv\n",
            "337 block17_4\n",
            "338 block17_4_ac\n",
            "339 conv2d_94\n",
            "340 batch_normalization_94\n",
            "341 activation_94\n",
            "342 conv2d_95\n",
            "343 batch_normalization_95\n",
            "344 activation_95\n",
            "345 conv2d_93\n",
            "346 conv2d_96\n",
            "347 batch_normalization_93\n",
            "348 batch_normalization_96\n",
            "349 activation_93\n",
            "350 activation_96\n",
            "351 block17_5_mixed\n",
            "352 block17_5_conv\n",
            "353 block17_5\n",
            "354 block17_5_ac\n",
            "355 conv2d_98\n",
            "356 batch_normalization_98\n",
            "357 activation_98\n",
            "358 conv2d_99\n",
            "359 batch_normalization_99\n",
            "360 activation_99\n",
            "361 conv2d_97\n",
            "362 conv2d_100\n",
            "363 batch_normalization_97\n",
            "364 batch_normalization_100\n",
            "365 activation_97\n",
            "366 activation_100\n",
            "367 block17_6_mixed\n",
            "368 block17_6_conv\n",
            "369 block17_6\n",
            "370 block17_6_ac\n",
            "371 conv2d_102\n",
            "372 batch_normalization_102\n",
            "373 activation_102\n",
            "374 conv2d_103\n",
            "375 batch_normalization_103\n",
            "376 activation_103\n",
            "377 conv2d_101\n",
            "378 conv2d_104\n",
            "379 batch_normalization_101\n",
            "380 batch_normalization_104\n",
            "381 activation_101\n",
            "382 activation_104\n",
            "383 block17_7_mixed\n",
            "384 block17_7_conv\n",
            "385 block17_7\n",
            "386 block17_7_ac\n",
            "387 conv2d_106\n",
            "388 batch_normalization_106\n",
            "389 activation_106\n",
            "390 conv2d_107\n",
            "391 batch_normalization_107\n",
            "392 activation_107\n",
            "393 conv2d_105\n",
            "394 conv2d_108\n",
            "395 batch_normalization_105\n",
            "396 batch_normalization_108\n",
            "397 activation_105\n",
            "398 activation_108\n",
            "399 block17_8_mixed\n",
            "400 block17_8_conv\n",
            "401 block17_8\n",
            "402 block17_8_ac\n",
            "403 conv2d_110\n",
            "404 batch_normalization_110\n",
            "405 activation_110\n",
            "406 conv2d_111\n",
            "407 batch_normalization_111\n",
            "408 activation_111\n",
            "409 conv2d_109\n",
            "410 conv2d_112\n",
            "411 batch_normalization_109\n",
            "412 batch_normalization_112\n",
            "413 activation_109\n",
            "414 activation_112\n",
            "415 block17_9_mixed\n",
            "416 block17_9_conv\n",
            "417 block17_9\n",
            "418 block17_9_ac\n",
            "419 conv2d_114\n",
            "420 batch_normalization_114\n",
            "421 activation_114\n",
            "422 conv2d_115\n",
            "423 batch_normalization_115\n",
            "424 activation_115\n",
            "425 conv2d_113\n",
            "426 conv2d_116\n",
            "427 batch_normalization_113\n",
            "428 batch_normalization_116\n",
            "429 activation_113\n",
            "430 activation_116\n",
            "431 block17_10_mixed\n",
            "432 block17_10_conv\n",
            "433 block17_10\n",
            "434 block17_10_ac\n",
            "435 conv2d_118\n",
            "436 batch_normalization_118\n",
            "437 activation_118\n",
            "438 conv2d_119\n",
            "439 batch_normalization_119\n",
            "440 activation_119\n",
            "441 conv2d_117\n",
            "442 conv2d_120\n",
            "443 batch_normalization_117\n",
            "444 batch_normalization_120\n",
            "445 activation_117\n",
            "446 activation_120\n",
            "447 block17_11_mixed\n",
            "448 block17_11_conv\n",
            "449 block17_11\n",
            "450 block17_11_ac\n",
            "451 conv2d_122\n",
            "452 batch_normalization_122\n",
            "453 activation_122\n",
            "454 conv2d_123\n",
            "455 batch_normalization_123\n",
            "456 activation_123\n",
            "457 conv2d_121\n",
            "458 conv2d_124\n",
            "459 batch_normalization_121\n",
            "460 batch_normalization_124\n",
            "461 activation_121\n",
            "462 activation_124\n",
            "463 block17_12_mixed\n",
            "464 block17_12_conv\n",
            "465 block17_12\n",
            "466 block17_12_ac\n",
            "467 conv2d_126\n",
            "468 batch_normalization_126\n",
            "469 activation_126\n",
            "470 conv2d_127\n",
            "471 batch_normalization_127\n",
            "472 activation_127\n",
            "473 conv2d_125\n",
            "474 conv2d_128\n",
            "475 batch_normalization_125\n",
            "476 batch_normalization_128\n",
            "477 activation_125\n",
            "478 activation_128\n",
            "479 block17_13_mixed\n",
            "480 block17_13_conv\n",
            "481 block17_13\n",
            "482 block17_13_ac\n",
            "483 conv2d_130\n",
            "484 batch_normalization_130\n",
            "485 activation_130\n",
            "486 conv2d_131\n",
            "487 batch_normalization_131\n",
            "488 activation_131\n",
            "489 conv2d_129\n",
            "490 conv2d_132\n",
            "491 batch_normalization_129\n",
            "492 batch_normalization_132\n",
            "493 activation_129\n",
            "494 activation_132\n",
            "495 block17_14_mixed\n",
            "496 block17_14_conv\n",
            "497 block17_14\n",
            "498 block17_14_ac\n",
            "499 conv2d_134\n",
            "500 batch_normalization_134\n",
            "501 activation_134\n",
            "502 conv2d_135\n",
            "503 batch_normalization_135\n",
            "504 activation_135\n",
            "505 conv2d_133\n",
            "506 conv2d_136\n",
            "507 batch_normalization_133\n",
            "508 batch_normalization_136\n",
            "509 activation_133\n",
            "510 activation_136\n",
            "511 block17_15_mixed\n",
            "512 block17_15_conv\n",
            "513 block17_15\n",
            "514 block17_15_ac\n",
            "515 conv2d_138\n",
            "516 batch_normalization_138\n",
            "517 activation_138\n",
            "518 conv2d_139\n",
            "519 batch_normalization_139\n",
            "520 activation_139\n",
            "521 conv2d_137\n",
            "522 conv2d_140\n",
            "523 batch_normalization_137\n",
            "524 batch_normalization_140\n",
            "525 activation_137\n",
            "526 activation_140\n",
            "527 block17_16_mixed\n",
            "528 block17_16_conv\n",
            "529 block17_16\n",
            "530 block17_16_ac\n",
            "531 conv2d_142\n",
            "532 batch_normalization_142\n",
            "533 activation_142\n",
            "534 conv2d_143\n",
            "535 batch_normalization_143\n",
            "536 activation_143\n",
            "537 conv2d_141\n",
            "538 conv2d_144\n",
            "539 batch_normalization_141\n",
            "540 batch_normalization_144\n",
            "541 activation_141\n",
            "542 activation_144\n",
            "543 block17_17_mixed\n",
            "544 block17_17_conv\n",
            "545 block17_17\n",
            "546 block17_17_ac\n",
            "547 conv2d_146\n",
            "548 batch_normalization_146\n",
            "549 activation_146\n",
            "550 conv2d_147\n",
            "551 batch_normalization_147\n",
            "552 activation_147\n",
            "553 conv2d_145\n",
            "554 conv2d_148\n",
            "555 batch_normalization_145\n",
            "556 batch_normalization_148\n",
            "557 activation_145\n",
            "558 activation_148\n",
            "559 block17_18_mixed\n",
            "560 block17_18_conv\n",
            "561 block17_18\n",
            "562 block17_18_ac\n",
            "563 conv2d_150\n",
            "564 batch_normalization_150\n",
            "565 activation_150\n",
            "566 conv2d_151\n",
            "567 batch_normalization_151\n",
            "568 activation_151\n",
            "569 conv2d_149\n",
            "570 conv2d_152\n",
            "571 batch_normalization_149\n",
            "572 batch_normalization_152\n",
            "573 activation_149\n",
            "574 activation_152\n",
            "575 block17_19_mixed\n",
            "576 block17_19_conv\n",
            "577 block17_19\n",
            "578 block17_19_ac\n",
            "579 conv2d_154\n",
            "580 batch_normalization_154\n",
            "581 activation_154\n",
            "582 conv2d_155\n",
            "583 batch_normalization_155\n",
            "584 activation_155\n",
            "585 conv2d_153\n",
            "586 conv2d_156\n",
            "587 batch_normalization_153\n",
            "588 batch_normalization_156\n",
            "589 activation_153\n",
            "590 activation_156\n",
            "591 block17_20_mixed\n",
            "592 block17_20_conv\n",
            "593 block17_20\n",
            "594 block17_20_ac\n",
            "595 conv2d_161\n",
            "596 batch_normalization_161\n",
            "597 activation_161\n",
            "598 conv2d_157\n",
            "599 conv2d_159\n",
            "600 conv2d_162\n",
            "601 batch_normalization_157\n",
            "602 batch_normalization_159\n",
            "603 batch_normalization_162\n",
            "604 activation_157\n",
            "605 activation_159\n",
            "606 activation_162\n",
            "607 conv2d_158\n",
            "608 conv2d_160\n",
            "609 conv2d_163\n",
            "610 batch_normalization_158\n",
            "611 batch_normalization_160\n",
            "612 batch_normalization_163\n",
            "613 activation_158\n",
            "614 activation_160\n",
            "615 activation_163\n",
            "616 max_pooling2d_4\n",
            "617 mixed_7a\n",
            "618 conv2d_165\n",
            "619 batch_normalization_165\n",
            "620 activation_165\n",
            "621 conv2d_166\n",
            "622 batch_normalization_166\n",
            "623 activation_166\n",
            "624 conv2d_164\n",
            "625 conv2d_167\n",
            "626 batch_normalization_164\n",
            "627 batch_normalization_167\n",
            "628 activation_164\n",
            "629 activation_167\n",
            "630 block8_1_mixed\n",
            "631 block8_1_conv\n",
            "632 block8_1\n",
            "633 block8_1_ac\n",
            "634 conv2d_169\n",
            "635 batch_normalization_169\n",
            "636 activation_169\n",
            "637 conv2d_170\n",
            "638 batch_normalization_170\n",
            "639 activation_170\n",
            "640 conv2d_168\n",
            "641 conv2d_171\n",
            "642 batch_normalization_168\n",
            "643 batch_normalization_171\n",
            "644 activation_168\n",
            "645 activation_171\n",
            "646 block8_2_mixed\n",
            "647 block8_2_conv\n",
            "648 block8_2\n",
            "649 block8_2_ac\n",
            "650 conv2d_173\n",
            "651 batch_normalization_173\n",
            "652 activation_173\n",
            "653 conv2d_174\n",
            "654 batch_normalization_174\n",
            "655 activation_174\n",
            "656 conv2d_172\n",
            "657 conv2d_175\n",
            "658 batch_normalization_172\n",
            "659 batch_normalization_175\n",
            "660 activation_172\n",
            "661 activation_175\n",
            "662 block8_3_mixed\n",
            "663 block8_3_conv\n",
            "664 block8_3\n",
            "665 block8_3_ac\n",
            "666 conv2d_177\n",
            "667 batch_normalization_177\n",
            "668 activation_177\n",
            "669 conv2d_178\n",
            "670 batch_normalization_178\n",
            "671 activation_178\n",
            "672 conv2d_176\n",
            "673 conv2d_179\n",
            "674 batch_normalization_176\n",
            "675 batch_normalization_179\n",
            "676 activation_176\n",
            "677 activation_179\n",
            "678 block8_4_mixed\n",
            "679 block8_4_conv\n",
            "680 block8_4\n",
            "681 block8_4_ac\n",
            "682 conv2d_181\n",
            "683 batch_normalization_181\n",
            "684 activation_181\n",
            "685 conv2d_182\n",
            "686 batch_normalization_182\n",
            "687 activation_182\n",
            "688 conv2d_180\n",
            "689 conv2d_183\n",
            "690 batch_normalization_180\n",
            "691 batch_normalization_183\n",
            "692 activation_180\n",
            "693 activation_183\n",
            "694 block8_5_mixed\n",
            "695 block8_5_conv\n",
            "696 block8_5\n",
            "697 block8_5_ac\n",
            "698 conv2d_185\n",
            "699 batch_normalization_185\n",
            "700 activation_185\n",
            "701 conv2d_186\n",
            "702 batch_normalization_186\n",
            "703 activation_186\n",
            "704 conv2d_184\n",
            "705 conv2d_187\n",
            "706 batch_normalization_184\n",
            "707 batch_normalization_187\n",
            "708 activation_184\n",
            "709 activation_187\n",
            "710 block8_6_mixed\n",
            "711 block8_6_conv\n",
            "712 block8_6\n",
            "713 block8_6_ac\n",
            "714 conv2d_189\n",
            "715 batch_normalization_189\n",
            "716 activation_189\n",
            "717 conv2d_190\n",
            "718 batch_normalization_190\n",
            "719 activation_190\n",
            "720 conv2d_188\n",
            "721 conv2d_191\n",
            "722 batch_normalization_188\n",
            "723 batch_normalization_191\n",
            "724 activation_188\n",
            "725 activation_191\n",
            "726 block8_7_mixed\n",
            "727 block8_7_conv\n",
            "728 block8_7\n",
            "729 block8_7_ac\n",
            "730 conv2d_193\n",
            "731 batch_normalization_193\n",
            "732 activation_193\n",
            "733 conv2d_194\n",
            "734 batch_normalization_194\n",
            "735 activation_194\n",
            "736 conv2d_192\n",
            "737 conv2d_195\n",
            "738 batch_normalization_192\n",
            "739 batch_normalization_195\n",
            "740 activation_192\n",
            "741 activation_195\n",
            "742 block8_8_mixed\n",
            "743 block8_8_conv\n",
            "744 block8_8\n",
            "745 block8_8_ac\n",
            "746 conv2d_197\n",
            "747 batch_normalization_197\n",
            "748 activation_197\n",
            "749 conv2d_198\n",
            "750 batch_normalization_198\n",
            "751 activation_198\n",
            "752 conv2d_196\n",
            "753 conv2d_199\n",
            "754 batch_normalization_196\n",
            "755 batch_normalization_199\n",
            "756 activation_196\n",
            "757 activation_199\n",
            "758 block8_9_mixed\n",
            "759 block8_9_conv\n",
            "760 block8_9\n",
            "761 block8_9_ac\n",
            "762 conv2d_201\n",
            "763 batch_normalization_201\n",
            "764 activation_201\n",
            "765 conv2d_202\n",
            "766 batch_normalization_202\n",
            "767 activation_202\n",
            "768 conv2d_200\n",
            "769 conv2d_203\n",
            "770 batch_normalization_200\n",
            "771 batch_normalization_203\n",
            "772 activation_200\n",
            "773 activation_203\n",
            "774 block8_10_mixed\n",
            "775 block8_10_conv\n",
            "776 block8_10\n",
            "777 conv_7b\n",
            "778 conv_7b_bn\n",
            "779 conv_7b_ac\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNv2kGmRl4YY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "d393d0d2-6788-4695-fc52-43407cce3106"
      },
      "source": [
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation = 'relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(3, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0719 19:01:22.552197 140624009312128 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IDHmSsDl724",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c92e45ca-fd12-48d5-e8b0-4192f378866e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 149, 149, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 149, 149, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 149, 149, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 147, 147, 32) 9216        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 147, 147, 32) 96          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 147, 147, 32) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 147, 147, 64) 18432       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 147, 147, 64) 192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 147, 147, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 73, 73, 80)   240         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 73, 73, 80)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 71, 71, 192)  138240      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 71, 71, 192)  576         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 71, 71, 192)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 35, 35, 64)   192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 35, 35, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 35, 35, 96)   55296       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 35, 35, 48)   144         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 35, 35, 48)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 35, 35, 96)   18432       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 35, 35, 64)   76800       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 35, 35, 96)   82944       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 35, 35, 64)   12288       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 35, 35, 96)   288         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 35, 35, 96)   288         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 35, 35, 96)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 35, 35, 96)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed_5b (Concatenate)          (None, 35, 35, 320)  0           activation_6[0][0]               \n",
            "                                                                 activation_8[0][0]               \n",
            "                                                                 activation_11[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 35, 35, 32)   96          conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 35, 35, 32)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 35, 35, 48)   13824       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 35, 35, 32)   96          conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 35, 35, 48)   144         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 35, 35, 32)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 35, 35, 48)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 35, 35, 32)   9216        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 35, 35, 64)   27648       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 35, 35, 32)   96          conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 35, 35, 32)   96          conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 35, 35, 32)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 35, 35, 32)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_13[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_1_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_1 (Lambda)              (None, 35, 35, 320)  0           mixed_5b[0][0]                   \n",
            "                                                                 block35_1_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_ac (Activation)       (None, 35, 35, 320)  0           block35_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 35, 35, 32)   96          conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 35, 35, 32)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 35, 35, 48)   13824       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 35, 35, 32)   96          conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 35, 35, 48)   144         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 35, 35, 32)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 35, 35, 48)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 35, 35, 32)   9216        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 35, 35, 64)   27648       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 35, 35, 32)   96          conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 35, 35, 32)   96          conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 35, 35, 64)   192         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 35, 35, 32)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 35, 35, 32)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 35, 35, 64)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_2_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_2 (Lambda)              (None, 35, 35, 320)  0           block35_1_ac[0][0]               \n",
            "                                                                 block35_2_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_ac (Activation)       (None, 35, 35, 320)  0           block35_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 35, 35, 32)   96          conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 35, 35, 32)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 35, 35, 48)   13824       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 35, 35, 32)   96          conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 35, 35, 48)   144         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 35, 35, 32)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 35, 35, 48)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 35, 35, 32)   9216        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 35, 35, 64)   27648       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 35, 35, 32)   96          conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 35, 35, 32)   96          conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 35, 35, 64)   192         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 35, 35, 32)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 35, 35, 32)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 35, 35, 64)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_25[0][0]              \n",
            "                                                                 activation_27[0][0]              \n",
            "                                                                 activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_3_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_3 (Lambda)              (None, 35, 35, 320)  0           block35_2_ac[0][0]               \n",
            "                                                                 block35_3_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_ac (Activation)       (None, 35, 35, 320)  0           block35_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 35, 35, 32)   96          conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 35, 35, 32)   0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 35, 35, 48)   13824       activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 35, 35, 32)   96          conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 35, 35, 48)   144         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 35, 35, 32)   0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 35, 35, 48)   0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 35, 35, 32)   9216        activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 35, 35, 64)   27648       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 35, 35, 32)   96          conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 35, 35, 32)   96          conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 35, 35, 64)   192         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 35, 35, 32)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 35, 35, 32)   0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 35, 35, 64)   0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_31[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_4_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_4 (Lambda)              (None, 35, 35, 320)  0           block35_3_ac[0][0]               \n",
            "                                                                 block35_4_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_ac (Activation)       (None, 35, 35, 320)  0           block35_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 35, 35, 32)   96          conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 35, 35, 32)   0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 35, 35, 48)   13824       activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 35, 35, 32)   96          conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 35, 35, 48)   144         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 35, 35, 32)   0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 35, 35, 48)   0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 35, 35, 32)   9216        activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 35, 35, 64)   27648       activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 35, 35, 32)   96          conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 35, 35, 32)   96          conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 35, 35, 64)   192         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 35, 35, 32)   0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 35, 35, 32)   0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 35, 35, 64)   0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_37[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "                                                                 activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_5_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_5 (Lambda)              (None, 35, 35, 320)  0           block35_4_ac[0][0]               \n",
            "                                                                 block35_5_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_ac (Activation)       (None, 35, 35, 320)  0           block35_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 35, 35, 32)   96          conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 35, 35, 32)   0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 35, 35, 48)   13824       activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 35, 35, 32)   96          conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 35, 35, 48)   144         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 35, 35, 32)   0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 35, 35, 48)   0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 35, 35, 32)   9216        activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 35, 35, 64)   27648       activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 35, 35, 32)   96          conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 35, 35, 32)   96          conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 35, 35, 64)   192         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 35, 35, 32)   0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 35, 35, 32)   0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 35, 35, 64)   0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_43[0][0]              \n",
            "                                                                 activation_45[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_6_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_6 (Lambda)              (None, 35, 35, 320)  0           block35_5_ac[0][0]               \n",
            "                                                                 block35_6_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_ac (Activation)       (None, 35, 35, 320)  0           block35_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 35, 35, 32)   96          conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 35, 35, 32)   0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 35, 35, 48)   13824       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 35, 35, 32)   96          conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 35, 35, 48)   144         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 35, 35, 32)   0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 35, 35, 48)   0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 35, 35, 32)   9216        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 35, 35, 64)   27648       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 35, 35, 32)   96          conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 35, 35, 32)   96          conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 35, 35, 64)   192         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 35, 35, 32)   0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 35, 35, 32)   0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 35, 35, 64)   0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_49[0][0]              \n",
            "                                                                 activation_51[0][0]              \n",
            "                                                                 activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_7_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_7 (Lambda)              (None, 35, 35, 320)  0           block35_6_ac[0][0]               \n",
            "                                                                 block35_7_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_ac (Activation)       (None, 35, 35, 320)  0           block35_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 35, 35, 32)   96          conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 35, 35, 32)   0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 35, 35, 48)   13824       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 35, 35, 32)   96          conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 35, 35, 48)   144         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 35, 35, 32)   0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 35, 35, 48)   0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 35, 35, 32)   9216        activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 35, 35, 64)   27648       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 35, 35, 32)   96          conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 35, 35, 32)   96          conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 35, 35, 64)   192         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 35, 35, 32)   0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 35, 35, 32)   0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 35, 35, 64)   0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_55[0][0]              \n",
            "                                                                 activation_57[0][0]              \n",
            "                                                                 activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_8_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_8 (Lambda)              (None, 35, 35, 320)  0           block35_7_ac[0][0]               \n",
            "                                                                 block35_8_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_ac (Activation)       (None, 35, 35, 320)  0           block35_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 35, 35, 32)   96          conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 35, 35, 32)   0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 35, 35, 48)   13824       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 35, 35, 32)   96          conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 35, 35, 48)   144         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 35, 35, 32)   0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 35, 35, 48)   0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 35, 35, 32)   9216        activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 35, 35, 64)   27648       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 35, 35, 32)   96          conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 35, 35, 32)   96          conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 35, 35, 64)   192         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 35, 35, 32)   0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 35, 35, 32)   0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 35, 35, 64)   0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_61[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_9_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_9 (Lambda)              (None, 35, 35, 320)  0           block35_8_ac[0][0]               \n",
            "                                                                 block35_9_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_ac (Activation)       (None, 35, 35, 320)  0           block35_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 35, 35, 32)   96          conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 35, 35, 32)   0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 35, 35, 48)   13824       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 35, 35, 32)   96          conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 35, 35, 48)   144         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 35, 35, 32)   0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 35, 35, 48)   0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 35, 35, 32)   9216        activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 35, 35, 64)   27648       activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 35, 35, 32)   96          conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 35, 35, 32)   96          conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 35, 35, 64)   192         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 35, 35, 32)   0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 35, 35, 32)   0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 35, 35, 64)   0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_mixed (Concatenate)  (None, 35, 35, 128)  0           activation_67[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "                                                                 activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_conv (Conv2D)        (None, 35, 35, 320)  41280       block35_10_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block35_10 (Lambda)             (None, 35, 35, 320)  0           block35_9_ac[0][0]               \n",
            "                                                                 block35_10_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_ac (Activation)      (None, 35, 35, 320)  0           block35_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 35, 35, 256)  81920       block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 35, 35, 256)  768         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 35, 35, 256)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 35, 35, 256)  589824      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 35, 35, 256)  768         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 35, 35, 256)  0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 17, 17, 384)  1105920     block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 17, 17, 384)  884736      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 17, 17, 384)  1152        conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 17, 17, 384)  1152        conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 17, 17, 384)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 17, 17, 384)  0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 17, 17, 320)  0           block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed_6a (Concatenate)          (None, 17, 17, 1088) 0           activation_73[0][0]              \n",
            "                                                                 activation_76[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 17, 17, 128)  139264      mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 17, 17, 128)  384         conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 17, 17, 128)  0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 17, 17, 160)  143360      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 17, 17, 160)  480         conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 17, 17, 160)  0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 17, 17, 192)  208896      mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 17, 17, 192)  215040      activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 17, 17, 192)  576         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 17, 17, 192)  576         conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 17, 17, 192)  0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 17, 17, 192)  0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_77[0][0]              \n",
            "                                                                 activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_1_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_1 (Lambda)              (None, 17, 17, 1088) 0           mixed_6a[0][0]                   \n",
            "                                                                 block17_1_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_ac (Activation)       (None, 17, 17, 1088) 0           block17_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 17, 17, 128)  139264      block17_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 17, 17, 128)  384         conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 17, 17, 128)  0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 17, 17, 160)  143360      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 17, 17, 160)  480         conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 17, 17, 160)  0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 17, 17, 192)  208896      block17_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 17, 17, 192)  215040      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 17, 17, 192)  576         conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 17, 17, 192)  576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 17, 17, 192)  0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 17, 17, 192)  0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_81[0][0]              \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_2_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_2 (Lambda)              (None, 17, 17, 1088) 0           block17_1_ac[0][0]               \n",
            "                                                                 block17_2_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_ac (Activation)       (None, 17, 17, 1088) 0           block17_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 17, 17, 128)  139264      block17_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 17, 17, 128)  384         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 17, 17, 128)  0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 17, 17, 160)  143360      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 17, 17, 160)  480         conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 17, 17, 160)  0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 17, 17, 192)  208896      block17_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 17, 17, 192)  215040      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 17, 17, 192)  576         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 17, 17, 192)  576         conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 17, 17, 192)  0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 17, 17, 192)  0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_85[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_3_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_3 (Lambda)              (None, 17, 17, 1088) 0           block17_2_ac[0][0]               \n",
            "                                                                 block17_3_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_ac (Activation)       (None, 17, 17, 1088) 0           block17_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 17, 17, 128)  139264      block17_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 17, 17, 128)  384         conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 17, 17, 128)  0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 17, 17, 160)  143360      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 17, 17, 160)  480         conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 17, 17, 160)  0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 17, 17, 192)  208896      block17_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 17, 17, 192)  215040      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 17, 17, 192)  576         conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 17, 17, 192)  576         conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 17, 17, 192)  0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 17, 17, 192)  0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_89[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_4_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_4 (Lambda)              (None, 17, 17, 1088) 0           block17_3_ac[0][0]               \n",
            "                                                                 block17_4_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_ac (Activation)       (None, 17, 17, 1088) 0           block17_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 17, 17, 128)  139264      block17_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 17, 17, 128)  384         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 17, 17, 128)  0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 17, 17, 160)  143360      activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 17, 17, 160)  480         conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 17, 17, 160)  0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 17, 17, 192)  208896      block17_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 17, 17, 192)  215040      activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 17, 17, 192)  576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 17, 17, 192)  576         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 17, 17, 192)  0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 17, 17, 192)  0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_93[0][0]              \n",
            "                                                                 activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_5_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_5 (Lambda)              (None, 17, 17, 1088) 0           block17_4_ac[0][0]               \n",
            "                                                                 block17_5_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_ac (Activation)       (None, 17, 17, 1088) 0           block17_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 17, 17, 128)  139264      block17_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 17, 17, 128)  384         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 17, 17, 128)  0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 17, 17, 160)  143360      activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 17, 17, 160)  480         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 17, 17, 160)  0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 17, 17, 192)  208896      block17_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 17, 17, 192)  215040      activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 17, 17, 192)  576         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 17, 17, 192)  576         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 17, 17, 192)  0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 17, 17, 192)  0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_97[0][0]              \n",
            "                                                                 activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_6_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_6 (Lambda)              (None, 17, 17, 1088) 0           block17_5_ac[0][0]               \n",
            "                                                                 block17_6_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_ac (Activation)       (None, 17, 17, 1088) 0           block17_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 17, 17, 128)  139264      block17_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 17, 17, 128)  384         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 17, 17, 128)  0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 17, 17, 160)  143360      activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 17, 17, 160)  480         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 17, 17, 160)  0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 17, 17, 192)  208896      block17_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 17, 17, 192)  215040      activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 17, 17, 192)  576         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 17, 17, 192)  576         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 17, 17, 192)  0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 17, 17, 192)  0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_101[0][0]             \n",
            "                                                                 activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_7_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_7 (Lambda)              (None, 17, 17, 1088) 0           block17_6_ac[0][0]               \n",
            "                                                                 block17_7_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_ac (Activation)       (None, 17, 17, 1088) 0           block17_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 17, 17, 128)  139264      block17_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 17, 17, 128)  384         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 17, 17, 128)  0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 17, 17, 160)  143360      activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 17, 17, 160)  480         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 17, 17, 160)  0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 17, 17, 192)  208896      block17_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 17, 17, 192)  215040      activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 17, 17, 192)  576         conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 17, 17, 192)  576         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 17, 17, 192)  0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 17, 17, 192)  0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_105[0][0]             \n",
            "                                                                 activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_8_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_8 (Lambda)              (None, 17, 17, 1088) 0           block17_7_ac[0][0]               \n",
            "                                                                 block17_8_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_ac (Activation)       (None, 17, 17, 1088) 0           block17_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 17, 17, 128)  139264      block17_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 17, 17, 128)  384         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 17, 17, 128)  0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 17, 17, 160)  143360      activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 17, 17, 160)  480         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 17, 17, 160)  0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 17, 17, 192)  208896      block17_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 17, 17, 192)  215040      activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 17, 17, 192)  576         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 17, 17, 192)  576         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 17, 17, 192)  0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 17, 17, 192)  0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_109[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_9_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_9 (Lambda)              (None, 17, 17, 1088) 0           block17_8_ac[0][0]               \n",
            "                                                                 block17_9_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_ac (Activation)       (None, 17, 17, 1088) 0           block17_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 17, 17, 128)  139264      block17_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 17, 17, 128)  384         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 17, 17, 128)  0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 17, 17, 160)  143360      activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 17, 17, 160)  480         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 17, 17, 160)  0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 17, 17, 192)  208896      block17_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 17, 17, 192)  215040      activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 17, 17, 192)  576         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 17, 17, 192)  576         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 17, 17, 192)  0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 17, 17, 192)  0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_113[0][0]             \n",
            "                                                                 activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_10_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_10 (Lambda)             (None, 17, 17, 1088) 0           block17_9_ac[0][0]               \n",
            "                                                                 block17_10_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_ac (Activation)      (None, 17, 17, 1088) 0           block17_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 17, 17, 128)  139264      block17_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 17, 17, 128)  384         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 17, 17, 128)  0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 17, 17, 160)  143360      activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 17, 17, 160)  480         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 17, 17, 160)  0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 17, 17, 192)  208896      block17_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 17, 17, 192)  215040      activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 17, 17, 192)  576         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 17, 17, 192)  576         conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 17, 17, 192)  0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 17, 17, 192)  0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_117[0][0]             \n",
            "                                                                 activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_11_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_11 (Lambda)             (None, 17, 17, 1088) 0           block17_10_ac[0][0]              \n",
            "                                                                 block17_11_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_ac (Activation)      (None, 17, 17, 1088) 0           block17_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 17, 17, 128)  139264      block17_11_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 17, 17, 128)  384         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 17, 17, 128)  0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 17, 17, 160)  143360      activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 17, 17, 160)  480         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 17, 17, 160)  0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 17, 17, 192)  208896      block17_11_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 17, 17, 192)  215040      activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 17, 17, 192)  576         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 17, 17, 192)  576         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 17, 17, 192)  0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 17, 17, 192)  0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_121[0][0]             \n",
            "                                                                 activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_12_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_12 (Lambda)             (None, 17, 17, 1088) 0           block17_11_ac[0][0]              \n",
            "                                                                 block17_12_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_ac (Activation)      (None, 17, 17, 1088) 0           block17_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 17, 17, 128)  139264      block17_12_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 17, 17, 128)  384         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 17, 17, 128)  0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 17, 17, 160)  143360      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 17, 17, 160)  480         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 17, 17, 160)  0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 17, 17, 192)  208896      block17_12_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 17, 17, 192)  215040      activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 17, 17, 192)  576         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 17, 17, 192)  576         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 17, 17, 192)  0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 17, 17, 192)  0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_125[0][0]             \n",
            "                                                                 activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_13_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_13 (Lambda)             (None, 17, 17, 1088) 0           block17_12_ac[0][0]              \n",
            "                                                                 block17_13_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_ac (Activation)      (None, 17, 17, 1088) 0           block17_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 17, 17, 128)  139264      block17_13_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 17, 17, 128)  384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 17, 17, 128)  0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 17, 17, 160)  143360      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 17, 17, 160)  480         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 17, 17, 160)  0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 17, 17, 192)  208896      block17_13_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 17, 17, 192)  215040      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 17, 17, 192)  576         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 17, 17, 192)  576         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 17, 17, 192)  0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 17, 17, 192)  0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_129[0][0]             \n",
            "                                                                 activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_14_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_14 (Lambda)             (None, 17, 17, 1088) 0           block17_13_ac[0][0]              \n",
            "                                                                 block17_14_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_ac (Activation)      (None, 17, 17, 1088) 0           block17_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 17, 17, 128)  139264      block17_14_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 17, 17, 128)  384         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 17, 17, 128)  0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 17, 17, 160)  143360      activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 17, 17, 160)  480         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 17, 17, 160)  0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 17, 17, 192)  208896      block17_14_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 17, 17, 192)  215040      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 17, 17, 192)  576         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 17, 17, 192)  576         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 17, 17, 192)  0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 17, 17, 192)  0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_133[0][0]             \n",
            "                                                                 activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_15_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_15 (Lambda)             (None, 17, 17, 1088) 0           block17_14_ac[0][0]              \n",
            "                                                                 block17_15_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_ac (Activation)      (None, 17, 17, 1088) 0           block17_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 17, 17, 128)  139264      block17_15_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 17, 17, 128)  384         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 17, 17, 128)  0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 17, 17, 160)  143360      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 17, 17, 160)  480         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 17, 17, 160)  0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 17, 17, 192)  208896      block17_15_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 17, 17, 192)  215040      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 17, 17, 192)  576         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 17, 17, 192)  576         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 17, 17, 192)  0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 17, 17, 192)  0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_137[0][0]             \n",
            "                                                                 activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_16_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_16 (Lambda)             (None, 17, 17, 1088) 0           block17_15_ac[0][0]              \n",
            "                                                                 block17_16_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_ac (Activation)      (None, 17, 17, 1088) 0           block17_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 17, 17, 128)  139264      block17_16_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 17, 17, 128)  384         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 17, 17, 128)  0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 17, 17, 160)  143360      activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 17, 17, 160)  480         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 17, 17, 160)  0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 17, 17, 192)  208896      block17_16_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 17, 17, 192)  215040      activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 17, 17, 192)  576         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 17, 17, 192)  576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 17, 17, 192)  0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 17, 17, 192)  0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_141[0][0]             \n",
            "                                                                 activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_17_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_17 (Lambda)             (None, 17, 17, 1088) 0           block17_16_ac[0][0]              \n",
            "                                                                 block17_17_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_ac (Activation)      (None, 17, 17, 1088) 0           block17_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 17, 17, 128)  139264      block17_17_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 17, 17, 128)  384         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 17, 17, 128)  0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 17, 17, 160)  143360      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 17, 17, 160)  480         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 17, 17, 160)  0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 17, 17, 192)  208896      block17_17_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 17, 17, 192)  215040      activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 17, 17, 192)  576         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 17, 17, 192)  576         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 17, 17, 192)  0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 17, 17, 192)  0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_145[0][0]             \n",
            "                                                                 activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_18_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_18 (Lambda)             (None, 17, 17, 1088) 0           block17_17_ac[0][0]              \n",
            "                                                                 block17_18_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_ac (Activation)      (None, 17, 17, 1088) 0           block17_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 17, 17, 128)  139264      block17_18_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 17, 17, 128)  384         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 17, 17, 128)  0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 17, 17, 160)  143360      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 17, 17, 160)  480         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 17, 17, 160)  0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 17, 17, 192)  208896      block17_18_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 17, 17, 192)  215040      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 17, 17, 192)  576         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 17, 17, 192)  576         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 17, 17, 192)  0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 17, 17, 192)  0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_149[0][0]             \n",
            "                                                                 activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_19_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_19 (Lambda)             (None, 17, 17, 1088) 0           block17_18_ac[0][0]              \n",
            "                                                                 block17_19_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_ac (Activation)      (None, 17, 17, 1088) 0           block17_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 17, 17, 128)  139264      block17_19_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 17, 17, 128)  384         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 17, 17, 128)  0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 17, 17, 160)  143360      activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 17, 17, 160)  480         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 17, 17, 160)  0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 17, 17, 192)  208896      block17_19_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 17, 17, 192)  215040      activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 17, 17, 192)  576         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 17, 17, 192)  576         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 17, 17, 192)  0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 17, 17, 192)  0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_153[0][0]             \n",
            "                                                                 activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_20_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_20 (Lambda)             (None, 17, 17, 1088) 0           block17_19_ac[0][0]              \n",
            "                                                                 block17_20_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_ac (Activation)      (None, 17, 17, 1088) 0           block17_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 17, 17, 256)  768         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 17, 17, 256)  0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 17, 17, 288)  663552      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 17, 17, 256)  768         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 17, 17, 256)  768         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 17, 17, 288)  864         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 17, 17, 256)  0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 17, 17, 256)  0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 17, 17, 288)  0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 8, 8, 384)    884736      activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 8, 8, 288)    663552      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 8, 8, 320)    829440      activation_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 8, 8, 384)    1152        conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 8, 8, 288)    864         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 8, 8, 320)    960         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 8, 8, 384)    0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 8, 8, 288)    0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 8, 8, 320)    0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 1088)   0           block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed_7a (Concatenate)          (None, 8, 8, 2080)   0           activation_158[0][0]             \n",
            "                                                                 activation_160[0][0]             \n",
            "                                                                 activation_163[0][0]             \n",
            "                                                                 max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 8, 8, 192)    576         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 8, 8, 192)    0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 8, 8, 224)    129024      activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 8, 8, 224)    672         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 8, 8, 224)    0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 8, 8, 256)    172032      activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 8, 8, 192)    576         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 8, 8, 256)    768         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 8, 8, 192)    0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 8, 8, 256)    0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_164[0][0]             \n",
            "                                                                 activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_1_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_1 (Lambda)               (None, 8, 8, 2080)   0           mixed_7a[0][0]                   \n",
            "                                                                 block8_1_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_ac (Activation)        (None, 8, 8, 2080)   0           block8_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 8, 8, 192)    576         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 8, 8, 192)    0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 8, 8, 224)    129024      activation_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 8, 8, 224)    672         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 8, 8, 224)    0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 8, 8, 256)    172032      activation_170[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 8, 8, 192)    576         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 8, 8, 256)    768         conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 8, 8, 192)    0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 8, 8, 256)    0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_168[0][0]             \n",
            "                                                                 activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_2_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_2 (Lambda)               (None, 8, 8, 2080)   0           block8_1_ac[0][0]                \n",
            "                                                                 block8_2_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_ac (Activation)        (None, 8, 8, 2080)   0           block8_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 8, 8, 192)    576         conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 8, 8, 192)    0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 8, 8, 224)    129024      activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 8, 8, 224)    672         conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 8, 8, 224)    0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 8, 8, 256)    172032      activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 8, 8, 192)    576         conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 8, 8, 256)    768         conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 8, 8, 192)    0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 8, 8, 256)    0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_172[0][0]             \n",
            "                                                                 activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_3_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_3 (Lambda)               (None, 8, 8, 2080)   0           block8_2_ac[0][0]                \n",
            "                                                                 block8_3_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_ac (Activation)        (None, 8, 8, 2080)   0           block8_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 8, 8, 192)    576         conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 8, 8, 192)    0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 8, 8, 224)    129024      activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 8, 8, 224)    672         conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 8, 8, 224)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 8, 8, 256)    172032      activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 8, 8, 192)    576         conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 8, 8, 256)    768         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 8, 8, 192)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 8, 8, 256)    0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_176[0][0]             \n",
            "                                                                 activation_179[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_4_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_4 (Lambda)               (None, 8, 8, 2080)   0           block8_3_ac[0][0]                \n",
            "                                                                 block8_4_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_ac (Activation)        (None, 8, 8, 2080)   0           block8_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 8, 8, 192)    576         conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 8, 8, 192)    0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 8, 8, 224)    129024      activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 8, 8, 224)    672         conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 8, 8, 224)    0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 8, 8, 256)    172032      activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 8, 8, 192)    576         conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 8, 8, 256)    768         conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 8, 8, 192)    0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 8, 8, 256)    0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_180[0][0]             \n",
            "                                                                 activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_5_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_5 (Lambda)               (None, 8, 8, 2080)   0           block8_4_ac[0][0]                \n",
            "                                                                 block8_5_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_ac (Activation)        (None, 8, 8, 2080)   0           block8_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 8, 8, 192)    576         conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 8, 8, 192)    0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 8, 8, 224)    129024      activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 8, 8, 224)    672         conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 8, 8, 224)    0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 8, 8, 256)    172032      activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 8, 8, 192)    576         conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 8, 8, 256)    768         conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 8, 8, 192)    0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 8, 8, 256)    0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_184[0][0]             \n",
            "                                                                 activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_6_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_6 (Lambda)               (None, 8, 8, 2080)   0           block8_5_ac[0][0]                \n",
            "                                                                 block8_6_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_ac (Activation)        (None, 8, 8, 2080)   0           block8_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 8, 8, 192)    576         conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 8, 8, 192)    0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 8, 8, 224)    129024      activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 8, 8, 224)    672         conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 8, 8, 224)    0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 8, 8, 256)    172032      activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 8, 8, 192)    576         conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 8, 8, 256)    768         conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 8, 8, 192)    0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 8, 8, 256)    0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_188[0][0]             \n",
            "                                                                 activation_191[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_7_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_7 (Lambda)               (None, 8, 8, 2080)   0           block8_6_ac[0][0]                \n",
            "                                                                 block8_7_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_ac (Activation)        (None, 8, 8, 2080)   0           block8_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 8, 8, 192)    576         conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 8, 8, 192)    0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 8, 8, 224)    129024      activation_193[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 8, 8, 224)    672         conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 8, 8, 224)    0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 8, 8, 256)    172032      activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 8, 8, 192)    576         conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 8, 8, 256)    768         conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 8, 8, 192)    0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 8, 8, 256)    0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_192[0][0]             \n",
            "                                                                 activation_195[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_8_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_8 (Lambda)               (None, 8, 8, 2080)   0           block8_7_ac[0][0]                \n",
            "                                                                 block8_8_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_ac (Activation)        (None, 8, 8, 2080)   0           block8_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 8, 8, 192)    399360      block8_8_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 8, 8, 192)    576         conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 8, 8, 192)    0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 8, 8, 224)    129024      activation_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 8, 8, 224)    672         conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_198 (Activation)     (None, 8, 8, 224)    0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 8, 8, 192)    399360      block8_8_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 8, 8, 256)    172032      activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 8, 8, 192)    576         conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 8, 8, 256)    768         conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_196 (Activation)     (None, 8, 8, 192)    0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_199 (Activation)     (None, 8, 8, 256)    0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_196[0][0]             \n",
            "                                                                 activation_199[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_9_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_9 (Lambda)               (None, 8, 8, 2080)   0           block8_8_ac[0][0]                \n",
            "                                                                 block8_9_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_ac (Activation)        (None, 8, 8, 2080)   0           block8_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 8, 8, 192)    399360      block8_9_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_201 (BatchN (None, 8, 8, 192)    576         conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_201 (Activation)     (None, 8, 8, 192)    0           batch_normalization_201[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 8, 8, 224)    129024      activation_201[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_202 (BatchN (None, 8, 8, 224)    672         conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_202 (Activation)     (None, 8, 8, 224)    0           batch_normalization_202[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 8, 8, 192)    399360      block8_9_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 8, 8, 256)    172032      activation_202[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 8, 8, 192)    576         conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_203 (BatchN (None, 8, 8, 256)    768         conv2d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_200 (Activation)     (None, 8, 8, 192)    0           batch_normalization_200[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_203 (Activation)     (None, 8, 8, 256)    0           batch_normalization_203[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_10_mixed (Concatenate)   (None, 8, 8, 448)    0           activation_200[0][0]             \n",
            "                                                                 activation_203[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_10_conv (Conv2D)         (None, 8, 8, 2080)   933920      block8_10_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_10 (Lambda)              (None, 8, 8, 2080)   0           block8_9_ac[0][0]                \n",
            "                                                                 block8_10_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b (Conv2D)                (None, 8, 8, 1536)   3194880     block8_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b_bn (BatchNormalization) (None, 8, 8, 1536)   4608        conv_7b[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b_ac (Activation)         (None, 8, 8, 1536)   0           conv_7b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 1536)         0           conv_7b_ac[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1024)         1573888     global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 3)            3075        dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 55,913,699\n",
            "Trainable params: 55,853,155\n",
            "Non-trainable params: 60,544\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXAD7-HtnFvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Niie7zTDnc_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_caYBXQsnhUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Baixar as imagens do exame de citologia cervical\n",
        "!wget -cq https://citologia-cervical.s3-sa-east-1.amazonaws.com/citologia.zip\n",
        "!unzip -qq citologia.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlRzT880nlbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen=ImageDataGenerator(preprocessing_function = preprocess_input) # incluÃ­do nas dependÃªncias\n",
        "\n",
        "validation_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtUnuy6Dnpsc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6533d564-9e26-424c-afcc-12b414b3dcbe"
      },
      "source": [
        "training_set = train_datagen.flow_from_directory('train',\n",
        "                                                 target_size = (img_width, img_height),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical',\n",
        "                                                 shuffle=True)\n",
        "\n",
        "validation_set = validation_datagen.flow_from_directory('valid',\n",
        "                                                        target_size = (img_width, img_height),\n",
        "                                                        color_mode='rgb',\n",
        "                                                        batch_size = 32,\n",
        "                                                        class_mode = 'categorical',\n",
        "                                                        shuffle=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 423 images belonging to 3 classes.\n",
            "Found 105 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZjYQD1fnulc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "172d1aaa-8188-4618-9ea6-991978974036"
      },
      "source": [
        "history = model.fit_generator(training_set,\n",
        "                    steps_per_epoch=528/32,\n",
        "                    epochs = 20,\n",
        "                    validation_data = validation_set,\n",
        "                    validation_steps = 105/32)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "17/16 [==============================] - 15s 909ms/step - loss: 3.2351 - acc: 0.3693 - val_loss: 1.2612 - val_acc: 0.4095\n",
            "Epoch 2/20\n",
            "17/16 [==============================] - 6s 380ms/step - loss: 1.4583 - acc: 0.3983 - val_loss: 1.2626 - val_acc: 0.4952\n",
            "Epoch 3/20\n",
            "17/16 [==============================] - 6s 381ms/step - loss: 1.1476 - acc: 0.4556 - val_loss: 0.9860 - val_acc: 0.5429\n",
            "Epoch 4/20\n",
            "17/16 [==============================] - 7s 383ms/step - loss: 1.0098 - acc: 0.5102 - val_loss: 2.2511 - val_acc: 0.3905\n",
            "Epoch 5/20\n",
            "17/16 [==============================] - 6s 371ms/step - loss: 1.0298 - acc: 0.5074 - val_loss: 1.5250 - val_acc: 0.4952\n",
            "Epoch 6/20\n",
            "17/16 [==============================] - 7s 386ms/step - loss: 1.0103 - acc: 0.5156 - val_loss: 1.5859 - val_acc: 0.4286\n",
            "Epoch 7/20\n",
            "17/16 [==============================] - 7s 386ms/step - loss: 0.9919 - acc: 0.5218 - val_loss: 1.0573 - val_acc: 0.5524\n",
            "Epoch 8/20\n",
            "17/16 [==============================] - 7s 389ms/step - loss: 0.8906 - acc: 0.5821 - val_loss: 1.4214 - val_acc: 0.4000\n",
            "Epoch 9/20\n",
            "17/16 [==============================] - 6s 376ms/step - loss: 0.9431 - acc: 0.5333 - val_loss: 1.2019 - val_acc: 0.4571\n",
            "Epoch 10/20\n",
            "17/16 [==============================] - 7s 391ms/step - loss: 0.9188 - acc: 0.5900 - val_loss: 1.1944 - val_acc: 0.5429\n",
            "Epoch 11/20\n",
            "17/16 [==============================] - 7s 393ms/step - loss: 0.9039 - acc: 0.6171 - val_loss: 0.8753 - val_acc: 0.5714\n",
            "Epoch 12/20\n",
            "17/16 [==============================] - 7s 394ms/step - loss: 0.9082 - acc: 0.5969 - val_loss: 1.1001 - val_acc: 0.4667\n",
            "Epoch 13/20\n",
            "17/16 [==============================] - 7s 393ms/step - loss: 0.7770 - acc: 0.6300 - val_loss: 1.2884 - val_acc: 0.4952\n",
            "Epoch 14/20\n",
            "17/16 [==============================] - 6s 380ms/step - loss: 0.8526 - acc: 0.5832 - val_loss: 1.2457 - val_acc: 0.5619\n",
            "Epoch 15/20\n",
            "17/16 [==============================] - 7s 395ms/step - loss: 0.7474 - acc: 0.6533 - val_loss: 1.9380 - val_acc: 0.4000\n",
            "Epoch 16/20\n",
            "17/16 [==============================] - 7s 396ms/step - loss: 0.8178 - acc: 0.6397 - val_loss: 1.4869 - val_acc: 0.5143\n",
            "Epoch 17/20\n",
            "17/16 [==============================] - 7s 396ms/step - loss: 0.7218 - acc: 0.6920 - val_loss: 1.1861 - val_acc: 0.4762\n",
            "Epoch 18/20\n",
            "17/16 [==============================] - 7s 397ms/step - loss: 0.7240 - acc: 0.6950 - val_loss: 1.4017 - val_acc: 0.6095\n",
            "Epoch 19/20\n",
            "17/16 [==============================] - 7s 385ms/step - loss: 0.8124 - acc: 0.6591 - val_loss: 1.3539 - val_acc: 0.5238\n",
            "Epoch 20/20\n",
            "17/16 [==============================] - 7s 400ms/step - loss: 0.7938 - acc: 0.6649 - val_loss: 1.6881 - val_acc: 0.4190\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-3L4VFmn6oU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers[:516]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[516:]:\n",
        "   layer.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC04FoyQn_08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import SGD\n",
        "model.compile(optimizer=SGD(lr=0.000001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id57dBEioFQV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "410fd61e-e7d9-476c-e719-6fd095dc683d"
      },
      "source": [
        "from google.colab import drive\n",
        "from keras.callbacks import *\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "filepath=\"/content/drive/My Drive/Colab Notebooks/log/inceptionresnetv2:{epoch:03d}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9Fx7b3koLuN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8ec8ebd8-6bb0-4508-ec63-244a9f56eea0"
      },
      "source": [
        "# Fine-tune\n",
        "history = model.fit_generator(training_set,\n",
        "                    steps_per_epoch=528/32,\n",
        "                    epochs = 100,\n",
        "                    validation_data = validation_set,\n",
        "                    validation_steps = 105/32,\n",
        "                    callbacks=callbacks_list)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "17/16 [==============================] - 27s 2s/step - loss: 0.6484 - acc: 0.6865 - val_loss: 1.0485 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.52381, saving model to /content/drive/My Drive/Colab Notebooks/log/inceptionresnetv2:001-val_acc:0.524.hdf5\n",
            "Epoch 2/100\n",
            "17/16 [==============================] - 10s 579ms/step - loss: 0.6358 - acc: 0.7086 - val_loss: 1.0085 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.52381 to 0.55238, saving model to /content/drive/My Drive/Colab Notebooks/log/inceptionresnetv2:002-val_acc:0.552.hdf5\n",
            "Epoch 3/100\n",
            "17/16 [==============================] - 10s 585ms/step - loss: 0.6473 - acc: 0.7093 - val_loss: 1.1011 - val_acc: 0.4476\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.55238\n",
            "Epoch 4/100\n",
            "17/16 [==============================] - 10s 564ms/step - loss: 0.6597 - acc: 0.7163 - val_loss: 1.0337 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.55238\n",
            "Epoch 5/100\n",
            "17/16 [==============================] - 10s 590ms/step - loss: 0.6258 - acc: 0.7111 - val_loss: 1.0834 - val_acc: 0.5048\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.55238\n",
            "Epoch 6/100\n",
            "17/16 [==============================] - 10s 591ms/step - loss: 0.6400 - acc: 0.7351 - val_loss: 0.9935 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.55238\n",
            "Epoch 7/100\n",
            "17/16 [==============================] - 10s 593ms/step - loss: 0.6224 - acc: 0.7332 - val_loss: 1.1277 - val_acc: 0.5048\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.55238\n",
            "Epoch 8/100\n",
            "17/16 [==============================] - 10s 595ms/step - loss: 0.6451 - acc: 0.6987 - val_loss: 1.1043 - val_acc: 0.4952\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.55238\n",
            "Epoch 9/100\n",
            "17/16 [==============================] - 10s 577ms/step - loss: 0.6234 - acc: 0.7139 - val_loss: 0.9756 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.55238\n",
            "Epoch 10/100\n",
            "17/16 [==============================] - 10s 601ms/step - loss: 0.6107 - acc: 0.7222 - val_loss: 1.0435 - val_acc: 0.5333\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.55238\n",
            "Epoch 11/100\n",
            "17/16 [==============================] - 10s 604ms/step - loss: 0.6241 - acc: 0.7247 - val_loss: 1.0566 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.55238\n",
            "Epoch 12/100\n",
            "17/16 [==============================] - 10s 605ms/step - loss: 0.6585 - acc: 0.7234 - val_loss: 1.0795 - val_acc: 0.4762\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.55238\n",
            "Epoch 13/100\n",
            "17/16 [==============================] - 10s 607ms/step - loss: 0.6026 - acc: 0.7339 - val_loss: 1.0821 - val_acc: 0.4952\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.55238\n",
            "Epoch 14/100\n",
            "17/16 [==============================] - 10s 586ms/step - loss: 0.6398 - acc: 0.7208 - val_loss: 1.0490 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.55238\n",
            "Epoch 15/100\n",
            "17/16 [==============================] - 10s 607ms/step - loss: 0.6538 - acc: 0.7190 - val_loss: 1.0574 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.55238\n",
            "Epoch 16/100\n",
            "17/16 [==============================] - 10s 612ms/step - loss: 0.6135 - acc: 0.7264 - val_loss: 1.0399 - val_acc: 0.5048\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.55238\n",
            "Epoch 17/100\n",
            "17/16 [==============================] - 10s 611ms/step - loss: 0.6170 - acc: 0.7284 - val_loss: 1.0034 - val_acc: 0.5143\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.55238\n",
            "Epoch 18/100\n",
            "17/16 [==============================] - 10s 591ms/step - loss: 0.6475 - acc: 0.7181 - val_loss: 1.0989 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.55238\n",
            "Epoch 19/100\n",
            "17/16 [==============================] - 10s 613ms/step - loss: 0.6146 - acc: 0.7079 - val_loss: 1.0543 - val_acc: 0.4952\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.55238\n",
            "Epoch 20/100\n",
            "17/16 [==============================] - 10s 616ms/step - loss: 0.6444 - acc: 0.7098 - val_loss: 1.1014 - val_acc: 0.4857\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.55238\n",
            "Epoch 21/100\n",
            "17/16 [==============================] - 10s 616ms/step - loss: 0.6042 - acc: 0.7222 - val_loss: 1.0224 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.55238\n",
            "Epoch 22/100\n",
            "17/16 [==============================] - 11s 618ms/step - loss: 0.6180 - acc: 0.7376 - val_loss: 0.9933 - val_acc: 0.5333\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.55238\n",
            "Epoch 23/100\n",
            "17/16 [==============================] - 10s 596ms/step - loss: 0.6405 - acc: 0.7312 - val_loss: 1.1444 - val_acc: 0.4762\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.55238\n",
            "Epoch 24/100\n",
            "17/16 [==============================] - 11s 620ms/step - loss: 0.5662 - acc: 0.7678 - val_loss: 0.9831 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.55238 to 0.56190, saving model to /content/drive/My Drive/Colab Notebooks/log/inceptionresnetv2:024-val_acc:0.562.hdf5\n",
            "Epoch 25/100\n",
            "17/16 [==============================] - 11s 624ms/step - loss: 0.6073 - acc: 0.7339 - val_loss: 1.0409 - val_acc: 0.5143\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.56190\n",
            "Epoch 26/100\n",
            "17/16 [==============================] - 11s 622ms/step - loss: 0.6442 - acc: 0.7167 - val_loss: 1.0175 - val_acc: 0.4952\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.56190\n",
            "Epoch 27/100\n",
            "17/16 [==============================] - 11s 621ms/step - loss: 0.6090 - acc: 0.7252 - val_loss: 1.1054 - val_acc: 0.4952\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.56190\n",
            "Epoch 28/100\n",
            "17/16 [==============================] - 10s 599ms/step - loss: 0.6149 - acc: 0.7448 - val_loss: 1.0557 - val_acc: 0.4952\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.56190\n",
            "Epoch 29/100\n",
            "17/16 [==============================] - 11s 623ms/step - loss: 0.6646 - acc: 0.7043 - val_loss: 1.0112 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00029: val_acc improved from 0.56190 to 0.57143, saving model to /content/drive/My Drive/Colab Notebooks/log/inceptionresnetv2:029-val_acc:0.571.hdf5\n",
            "Epoch 30/100\n",
            "17/16 [==============================] - 11s 625ms/step - loss: 0.6323 - acc: 0.7307 - val_loss: 1.0718 - val_acc: 0.4571\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.57143\n",
            "Epoch 31/100\n",
            "17/16 [==============================] - 11s 623ms/step - loss: 0.5906 - acc: 0.7664 - val_loss: 1.0838 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.57143\n",
            "Epoch 32/100\n",
            "17/16 [==============================] - 10s 601ms/step - loss: 0.6153 - acc: 0.7268 - val_loss: 1.0121 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.57143\n",
            "Epoch 33/100\n",
            "17/16 [==============================] - 11s 624ms/step - loss: 0.6021 - acc: 0.7167 - val_loss: 1.0009 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.57143\n",
            "Epoch 34/100\n",
            "17/16 [==============================] - 11s 626ms/step - loss: 0.6215 - acc: 0.7172 - val_loss: 1.0125 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.57143\n",
            "Epoch 35/100\n",
            "17/16 [==============================] - 11s 626ms/step - loss: 0.6375 - acc: 0.7049 - val_loss: 1.0831 - val_acc: 0.4762\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.57143\n",
            "Epoch 36/100\n",
            "17/16 [==============================] - 11s 626ms/step - loss: 0.5923 - acc: 0.7369 - val_loss: 1.0444 - val_acc: 0.5143\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.57143\n",
            "Epoch 37/100\n",
            "17/16 [==============================] - 10s 602ms/step - loss: 0.6544 - acc: 0.6861 - val_loss: 1.0268 - val_acc: 0.5048\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.57143\n",
            "Epoch 38/100\n",
            "17/16 [==============================] - 11s 626ms/step - loss: 0.6027 - acc: 0.7517 - val_loss: 1.1094 - val_acc: 0.5143\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.57143\n",
            "Epoch 39/100\n",
            "17/16 [==============================] - 11s 626ms/step - loss: 0.6173 - acc: 0.7203 - val_loss: 0.9830 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.57143\n",
            "Epoch 40/100\n",
            "17/16 [==============================] - 11s 626ms/step - loss: 0.5749 - acc: 0.7641 - val_loss: 1.0830 - val_acc: 0.4667\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.57143\n",
            "Epoch 41/100\n",
            "17/16 [==============================] - 11s 625ms/step - loss: 0.6143 - acc: 0.7443 - val_loss: 0.9506 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.57143\n",
            "Epoch 42/100\n",
            "17/16 [==============================] - 10s 603ms/step - loss: 0.6206 - acc: 0.7114 - val_loss: 1.0670 - val_acc: 0.4952\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.57143\n",
            "Epoch 43/100\n",
            "17/16 [==============================] - 11s 626ms/step - loss: 0.6206 - acc: 0.7130 - val_loss: 1.0887 - val_acc: 0.5048\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.57143\n",
            "Epoch 44/100\n",
            "17/16 [==============================] - 11s 626ms/step - loss: 0.5695 - acc: 0.7689 - val_loss: 0.9954 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.57143\n",
            "Epoch 45/100\n",
            "17/16 [==============================] - 11s 626ms/step - loss: 0.6099 - acc: 0.7393 - val_loss: 1.0538 - val_acc: 0.5143\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.57143\n",
            "Epoch 46/100\n",
            "17/16 [==============================] - 10s 602ms/step - loss: 0.5886 - acc: 0.7473 - val_loss: 0.9203 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00046: val_acc improved from 0.57143 to 0.57143, saving model to /content/drive/My Drive/Colab Notebooks/log/inceptionresnetv2:046-val_acc:0.571.hdf5\n",
            "Epoch 47/100\n",
            "17/16 [==============================] - 11s 630ms/step - loss: 0.6522 - acc: 0.7135 - val_loss: 1.0737 - val_acc: 0.5048\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.57143\n",
            "Epoch 48/100\n",
            "17/16 [==============================] - 11s 627ms/step - loss: 0.6212 - acc: 0.7517 - val_loss: 1.1160 - val_acc: 0.4762\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.57143\n",
            "Epoch 49/100\n",
            "17/16 [==============================] - 11s 628ms/step - loss: 0.6214 - acc: 0.7584 - val_loss: 1.0423 - val_acc: 0.4952\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.57143\n",
            "Epoch 50/100\n",
            "17/16 [==============================] - 11s 628ms/step - loss: 0.6111 - acc: 0.7326 - val_loss: 1.0820 - val_acc: 0.5143\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.57143\n",
            "Epoch 51/100\n",
            "17/16 [==============================] - 10s 602ms/step - loss: 0.6317 - acc: 0.7169 - val_loss: 0.9118 - val_acc: 0.5905\n",
            "\n",
            "Epoch 00051: val_acc improved from 0.57143 to 0.59048, saving model to /content/drive/My Drive/Colab Notebooks/log/inceptionresnetv2:051-val_acc:0.590.hdf5\n",
            "Epoch 52/100\n",
            "17/16 [==============================] - 11s 624ms/step - loss: 0.6316 - acc: 0.6925 - val_loss: 1.0791 - val_acc: 0.4857\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.59048\n",
            "Epoch 53/100\n",
            "17/16 [==============================] - 11s 626ms/step - loss: 0.6294 - acc: 0.7257 - val_loss: 1.0695 - val_acc: 0.4952\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.59048\n",
            "Epoch 54/100\n",
            "17/16 [==============================] - 11s 625ms/step - loss: 0.5860 - acc: 0.7554 - val_loss: 1.0426 - val_acc: 0.5048\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.59048\n",
            "Epoch 55/100\n",
            "17/16 [==============================] - 11s 625ms/step - loss: 0.5839 - acc: 0.7321 - val_loss: 0.9973 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.59048\n",
            "Epoch 56/100\n",
            "17/16 [==============================] - 10s 604ms/step - loss: 0.5898 - acc: 0.7608 - val_loss: 1.0854 - val_acc: 0.5143\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.59048\n",
            "Epoch 57/100\n",
            "17/16 [==============================] - 11s 626ms/step - loss: 0.6381 - acc: 0.7321 - val_loss: 0.9616 - val_acc: 0.5333\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.59048\n",
            "Epoch 58/100\n",
            "17/16 [==============================] - 11s 627ms/step - loss: 0.5706 - acc: 0.7646 - val_loss: 1.0246 - val_acc: 0.5143\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.59048\n",
            "Epoch 59/100\n",
            "17/16 [==============================] - 11s 627ms/step - loss: 0.5849 - acc: 0.7450 - val_loss: 1.0039 - val_acc: 0.6000\n",
            "\n",
            "Epoch 00059: val_acc improved from 0.59048 to 0.60000, saving model to /content/drive/My Drive/Colab Notebooks/log/inceptionresnetv2:059-val_acc:0.600.hdf5\n",
            "Epoch 60/100\n",
            "17/16 [==============================] - 10s 603ms/step - loss: 0.5977 - acc: 0.7589 - val_loss: 1.1810 - val_acc: 0.4190\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.60000\n",
            "Epoch 61/100\n",
            "17/16 [==============================] - 11s 624ms/step - loss: 0.5893 - acc: 0.7696 - val_loss: 0.9531 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.60000\n",
            "Epoch 62/100\n",
            "17/16 [==============================] - 11s 624ms/step - loss: 0.5935 - acc: 0.7505 - val_loss: 1.0221 - val_acc: 0.5143\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.60000\n",
            "Epoch 63/100\n",
            "17/16 [==============================] - 11s 625ms/step - loss: 0.6027 - acc: 0.7505 - val_loss: 1.0696 - val_acc: 0.5143\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.60000\n",
            "Epoch 64/100\n",
            "17/16 [==============================] - 11s 627ms/step - loss: 0.5812 - acc: 0.7664 - val_loss: 0.9837 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.60000\n",
            "Epoch 65/100\n",
            "17/16 [==============================] - 10s 605ms/step - loss: 0.6141 - acc: 0.7361 - val_loss: 1.0354 - val_acc: 0.5333\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.60000\n",
            "Epoch 66/100\n",
            "17/16 [==============================] - 11s 628ms/step - loss: 0.5815 - acc: 0.7388 - val_loss: 1.0415 - val_acc: 0.4762\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.60000\n",
            "Epoch 67/100\n",
            "17/16 [==============================] - 11s 625ms/step - loss: 0.6302 - acc: 0.7282 - val_loss: 1.0995 - val_acc: 0.5143\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.60000\n",
            "Epoch 68/100\n",
            "17/16 [==============================] - 11s 627ms/step - loss: 0.5855 - acc: 0.7528 - val_loss: 0.9764 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.60000\n",
            "Epoch 69/100\n",
            "17/16 [==============================] - 11s 625ms/step - loss: 0.5892 - acc: 0.7720 - val_loss: 0.9786 - val_acc: 0.5810\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.60000\n",
            "Epoch 70/100\n",
            "17/16 [==============================] - 10s 600ms/step - loss: 0.6285 - acc: 0.7250 - val_loss: 1.0418 - val_acc: 0.5143\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.60000\n",
            "Epoch 71/100\n",
            "17/16 [==============================] - 11s 623ms/step - loss: 0.6268 - acc: 0.7381 - val_loss: 1.0790 - val_acc: 0.4952\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.60000\n",
            "Epoch 72/100\n",
            "17/16 [==============================] - 11s 624ms/step - loss: 0.5805 - acc: 0.7498 - val_loss: 1.0060 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.60000\n",
            "Epoch 73/100\n",
            "17/16 [==============================] - 11s 623ms/step - loss: 0.5805 - acc: 0.7517 - val_loss: 1.0368 - val_acc: 0.4952\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.60000\n",
            "Epoch 74/100\n",
            "17/16 [==============================] - 10s 600ms/step - loss: 0.5744 - acc: 0.7435 - val_loss: 0.9557 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.60000\n",
            "Epoch 75/100\n",
            "17/16 [==============================] - 11s 624ms/step - loss: 0.5949 - acc: 0.7510 - val_loss: 1.0505 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.60000\n",
            "Epoch 76/100\n",
            "17/16 [==============================] - 11s 628ms/step - loss: 0.5908 - acc: 0.7450 - val_loss: 1.0247 - val_acc: 0.5048\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.60000\n",
            "Epoch 77/100\n",
            "17/16 [==============================] - 11s 628ms/step - loss: 0.6183 - acc: 0.7289 - val_loss: 1.0728 - val_acc: 0.5333\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.60000\n",
            "Epoch 78/100\n",
            "17/16 [==============================] - 11s 627ms/step - loss: 0.6046 - acc: 0.7374 - val_loss: 1.0398 - val_acc: 0.5333\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.60000\n",
            "Epoch 79/100\n",
            "17/16 [==============================] - 10s 603ms/step - loss: 0.5940 - acc: 0.7436 - val_loss: 0.9512 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.60000\n",
            "Epoch 80/100\n",
            "17/16 [==============================] - 11s 626ms/step - loss: 0.5798 - acc: 0.7528 - val_loss: 1.0914 - val_acc: 0.5048\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.60000\n",
            "Epoch 81/100\n",
            "17/16 [==============================] - 11s 627ms/step - loss: 0.6196 - acc: 0.7172 - val_loss: 0.9868 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.60000\n",
            "Epoch 82/100\n",
            "17/16 [==============================] - 11s 625ms/step - loss: 0.6357 - acc: 0.7337 - val_loss: 0.9862 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.60000\n",
            "Epoch 83/100\n",
            "17/16 [==============================] - 11s 628ms/step - loss: 0.5947 - acc: 0.7627 - val_loss: 1.1023 - val_acc: 0.4857\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.60000\n",
            "Epoch 84/100\n",
            "17/16 [==============================] - 10s 600ms/step - loss: 0.6230 - acc: 0.7250 - val_loss: 0.9812 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.60000\n",
            "Epoch 85/100\n",
            "17/16 [==============================] - 11s 625ms/step - loss: 0.5849 - acc: 0.7461 - val_loss: 1.0371 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.60000\n",
            "Epoch 86/100\n",
            "17/16 [==============================] - 11s 626ms/step - loss: 0.5614 - acc: 0.7621 - val_loss: 1.0584 - val_acc: 0.5333\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.60000\n",
            "Epoch 87/100\n",
            "17/16 [==============================] - 11s 626ms/step - loss: 0.6265 - acc: 0.7043 - val_loss: 1.0275 - val_acc: 0.5333\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.60000\n",
            "Epoch 88/100\n",
            "17/16 [==============================] - 10s 602ms/step - loss: 0.5625 - acc: 0.7639 - val_loss: 0.9520 - val_acc: 0.5333\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.60000\n",
            "Epoch 89/100\n",
            "17/16 [==============================] - 11s 624ms/step - loss: 0.5770 - acc: 0.7738 - val_loss: 1.0867 - val_acc: 0.5048\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.60000\n",
            "Epoch 90/100\n",
            "17/16 [==============================] - 11s 626ms/step - loss: 0.5747 - acc: 0.7554 - val_loss: 0.9530 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.60000\n",
            "Epoch 91/100\n",
            "17/16 [==============================] - 11s 625ms/step - loss: 0.5501 - acc: 0.7634 - val_loss: 1.0655 - val_acc: 0.5048\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.60000\n",
            "Epoch 92/100\n",
            "17/16 [==============================] - 11s 624ms/step - loss: 0.6102 - acc: 0.7406 - val_loss: 0.9342 - val_acc: 0.5810\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.60000\n",
            "Epoch 93/100\n",
            "17/16 [==============================] - 10s 602ms/step - loss: 0.5768 - acc: 0.7502 - val_loss: 1.0809 - val_acc: 0.5333\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.60000\n",
            "Epoch 94/100\n",
            "17/16 [==============================] - 11s 626ms/step - loss: 0.5746 - acc: 0.7523 - val_loss: 1.0467 - val_acc: 0.4952\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.60000\n",
            "Epoch 95/100\n",
            "17/16 [==============================] - 11s 627ms/step - loss: 0.5739 - acc: 0.7689 - val_loss: 0.9713 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.60000\n",
            "Epoch 96/100\n",
            "17/16 [==============================] - 11s 626ms/step - loss: 0.5906 - acc: 0.7547 - val_loss: 1.0375 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.60000\n",
            "Epoch 97/100\n",
            "17/16 [==============================] - 11s 626ms/step - loss: 0.5994 - acc: 0.7485 - val_loss: 0.9958 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.60000\n",
            "Epoch 98/100\n",
            "17/16 [==============================] - 10s 601ms/step - loss: 0.5817 - acc: 0.7626 - val_loss: 1.1509 - val_acc: 0.4476\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.60000\n",
            "Epoch 99/100\n",
            "17/16 [==============================] - 11s 624ms/step - loss: 0.5647 - acc: 0.7530 - val_loss: 0.8973 - val_acc: 0.5905\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.60000\n",
            "Epoch 100/100\n",
            "17/16 [==============================] - 11s 623ms/step - loss: 0.5640 - acc: 0.7584 - val_loss: 1.0314 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.60000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rImnQtq6qS8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Carregando o modelo com o peso melhor treinado (exemplo: carregando epoch 47, validation accuracy de 90.5%)\n",
        "\n",
        "model.load_weights('/content/drive/My Drive/Colab Notebooks/log/inceptionresnetv2:059-val_acc:0.600.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcHBBT-4r_CQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "96708640-40e9-408e-aa45-81029a81c403"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# GrÃ¡fico de treino - acurÃ¡cia\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# GrÃ¡fico de treino - perda\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzB7s1ZE44QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnXd4XMW5/z+j3rtkW5Zt2cbdBmNs\neieA6QQSehJIMdybEAJJfoGQkNz0ey9pBAIhodyE0EuA0EyxTbNx703ualbvXdr5/TFnds+ePbva\nlbWSLc/nefSsdvfsObNnz5nvvGXeEVJKDAaDwWAAiBnuBhgMBoPh8MGIgsFgMBi8GFEwGAwGgxcj\nCgaDwWDwYkTBYDAYDF6MKBgMBoPBixEFgyFMhBBPCiF+Eea2+4QQnzvU/RgMQ40RBYPBYDB4MaJg\nMBgMBi9GFAwjCstt830hxEYhRJsQ4jEhxCghxFtCiBYhxHtCiGzb9pcLIbYIIRqFEEuFEDNs7x0v\nhFhrfe45IMlxrEuFEOutz34qhDh2gG3+hhBilxCiXgjxmhCi0HpdCCF+L4SoFkI0CyE2CSFmW+9d\nLITYarWtXAjxvQGdMIPBgREFw0jkauB8YCpwGfAW8EMgH3XNfxtACDEVeAb4jvXem8DrQogEIUQC\n8C/gH0AO8IK1X6zPHg88DtwK5AJ/AV4TQiRG0lAhxLnAr4FrgDHAfuBZ6+0LgDOt75FpbVNnvfcY\ncKuUMh2YDXwQyXENhmAYUTCMRP4kpaySUpYDHwGfSSnXSSk7gVeA463trgXekFK+K6XsAe4HkoFT\ngZOBeOAPUsoeKeWLwCrbMRYBf5FSfial7JNS/h/QZX0uEm4EHpdSrpVSdgH3AKcIIYqBHiAdmA4I\nKeU2KWWl9bkeYKYQIkNK2SClXBvhcQ0GV4woGEYiVbb/O1yep1n/F6JG5gBIKT1AKTDWeq9c+leM\n3G/7fwLwXct11CiEaATGWZ+LBGcbWlHWwFgp5QfAg8BDQLUQ4lEhRIa16dXAxcB+IcQyIcQpER7X\nYHDFiILhaKYC1bkDyoeP6tjLgUpgrPWaZrzt/1Lgl1LKLNtfipTymUNsQyrKHVUOIKV8QEp5AjAT\n5Ub6vvX6KinlFUABys31fITHNRhcMaJgOJp5HrhECHGeECIe+C7KBfQpsBzoBb4thIgXQlwFnGj7\n7F+B24QQJ1kB4VQhxCVCiPQI2/AMcIsQYq4Vj/gVyt21TwixwNp/PNAGdAIeK+ZxoxAi03J7NQOe\nQzgPBoMXIwqGoxYp5Q7gJuBPQC0qKH2ZlLJbStkNXAXcDNSj4g8v2z67GvgGyr3TAOyyto20De8B\nPwZeQlknk4HrrLczUOLTgHIx1QH/a733JWCfEKIZuA0VmzAYDhlhFtkxGAwGg8ZYCgaDwWDwYkTB\nYDAYDF6MKBgMBoPBixEFg8FgMHiJG+4GREpeXp4sLi4e7mYYDAbDEcWaNWtqpZT5/W0XNVEQQjwO\nXApUSylnu7x/I/ADQAAtwH9IKTf0t9/i4mJWr1492M01GAyGEY0QYn//W0XXffQksDDE+3uBs6SU\nc4CfA49GsS0Gg8FgCIOoWQpSyg+tol7B3v/U9nQFUBStthgMBoMhPA6XQPPXUOWNXRFCLBJCrBZC\nrK6pqRnCZhkMBsPRxbAHmoUQ56BE4fRg20gpH8VyL82fPz9gCnZPTw9lZWV0dnZGrZ2HC0lJSRQV\nFREfHz/cTTEYDCOQYRUFa6WqvwEXSSnr+ts+GGVlZaSnp1NcXIx/UcuRhZSSuro6ysrKmDhx4nA3\nx2AwjECGzX0khBiPKjD2JSnlzkPZV2dnJ7m5uSNaEACEEOTm5h4VFpHBYBgeopmS+gxwNpAnhCgD\nfoJayQop5SPAfai68X+2OvNeKeX8QzjeoTb5iOBo+Z4Gg2F4iGb20fX9vP914OvROr7BcFRQ8i7k\nTYXsCf1vazCEweGSfXRE09jYyJ///OeIP3fxxRfT2NgYhRYZjhpeuBk++8twt8IwgjCiMAgEE4Xe\n3t6Qn3vzzTfJysqKVrMMI52+Huhuha7m4W6JYQQx7CmpI4G7776b3bt3M3fuXOLj40lKSiI7O5vt\n27ezc+dOrrzySkpLS+ns7OSOO+5g0aJFgK9kR2trKxdddBGnn346n376KWPHjuXVV18lOTl5mL+Z\n4bCmq0U99rQPbzsMI4oRJwr/9foWtlYM7shpZmEGP7lsVtD3f/Ob37B582bWr1/P0qVLueSSS9i8\nebM3bfTxxx8nJyeHjo4OFixYwNVXX01ubq7fPkpKSnjmmWf461//yjXXXMNLL73ETTfdNKjfwzDC\n0BZCd9vwtsMwohhxonA4cOKJJ/rNI3jggQd45ZVXACgtLaWkpCRAFCZOnMjcuXMBOOGEE9i3b9+Q\ntddwhKItBSMKhkFkxIlCqBH9UJGamur9f+nSpbz33nssX76clJQUzj77bNd5BomJid7/Y2Nj6ejo\nGJK2Go5gOi1LwbiPDIOICTQPAunp6bS0tLi+19TURHZ2NikpKWzfvp0VK1YMcesMIxavpWBEwTB4\njDhLYTjIzc3ltNNOY/bs2SQnJzNq1CjvewsXLuSRRx5hxowZTJs2jZNPPnkYW2oYUXgDzcZ9ZBg8\njCgMEk8//bTr64mJibz1lnsBWB03yMvLY/Pmzd7Xv/e97w16+wwjkK4m9WgshZFFZxMkZsAwVS8w\n7iOD4UjFpKSOPNrr4f5pULJ42JpgROFopbcbekxhvSMauyh4PMPbFsPg0FwOvR3QeGDYmmBE4Wjl\njbvg2RuGuxWGQ6HTNh/HWAsjg07LJTiMv6cRhaOVul1Qv3u4W2E4FLpsGW9GFEYGXlEYvpR0IwpH\nKx2N/iNNw5GHXRTMBLaRQYdVINNYCoYhp7NRjUpkwOqmhiOFLuM+GnEYS2FkMNDS2QB/+MMfaG8f\nhhu6swlknxlhHsl0NUOMlVVu0lJHBiamcIRSvwdaDnqfHnGi0Nvtu+hM2eUjl64WSLMmSpoJbCOD\nTu0+Gj5LwUxeGwhdLdDVCqn5EBPrVzr7/PPPp6CggOeff56uri4+//nP81//9V+0tbVxzTXXUFZW\nRl9fHz/+8Y+pqqqioqKCc845h7y8PJYsWTI07e+0LezT2QQZhUNzXMPg0tmsVlxrLjcW30jhMHAf\njTxReOtuOLhpcPc5eg5c9Bv1v/SoP4COekjN9yudvXjxYl588UVWrlyJlJLLL7+cDz/8kJqaGgoL\nC3njjTcAVRMpMzOT3/3udyxZsoS8vLzBbXMoOhyiYDgy6WqBtNHqf+M+GhkY99ERiKfP939bbUCg\ndvHixSxevJjjjz+eefPmsX37dkpKSpgzZw7vvvsuP/jBD/joo4/IzMwc4obbcFoKhvCo3QXNlcPd\nCkVvF/R1QbpxH40oOoz7aPDRI/po4bGW2EzMUP747la/t6WU3HPPPdx6660BH127di1vvvkmP/rR\njzjvvPO47777otvWYNiFwKSlhs9Tn4fCeXDN/w13S3zpqOlj1KOxFEYGxlI4AtGWQmqeyvxoq/Er\nnX3hhRfy+OOP09qqxKK8vJzq6moqKipISUnhpptu4vvf/z5r164FQpfdjhp+7qPG4NsdjnQ2qUD/\nUNNYqkoP1O0a+mO7oRME0i33kbEURgYjOaYghHgcuBSollLOdnl/OvAEMA+4V0p5f7TaMqhoSyEm\nHlJyobWK3IKx3tLZF110ETfccAOnnHIKAGlpaTz11FPs2rWL73//+8TExBAfH8/DDz8MwKJFi1i4\ncCGFhYXDF2gOFymHrXKjlyW/hm2vwV1bh/a4B6x1MOr3Hh7nQVsKKblqcGIshZHBCM8+ehJ4EPh7\nkPfrgW8DV0axDYOPVxTiICUPWqugvTagdPYdd9zh93zy5MlceOGFAbu7/fbbuf3226PWXFe0pRAT\nF35K6s7F8PI34NvrICUnem3rj7oSaK6Avl6IHULv54Hl6rGnTcWS0vKH7thuaLdfYjrEp5rJa24c\nDuIdCX29Pnf0SHQfSSk/RHX8wd6vllKuAnqi1Yaw8PRBw37o6w5/e4CYWIhLgPgU6D7Mls78952w\n5V/B3+9shLhkSM4J31IoX6M+V752cNo4UBpLATn0bq8DK9Q5A2jYO7THdkNbCokZkJASENs6JDx9\n0FQ2ePsbDup2wy8KoGqILcpDQQ/Q4pLMjOb+EEIsEkKsFkKsrqmpGdyd97Sr1NJwA66yFxAgrFMX\nE+ezHoaSng747XTY+qr/6x0NsPpx2NqPKCRnQVJm+KLQbHUSlesG1t7BQEpoKlX/t9cN3XE7GqB6\nK8y4TD1v2Dd0xw6GVxTSrYHJII4s1z0FD8w7sjPTarargV7NtuFuSfh0NKjH9NHQ2zls5dCPCFGQ\nUj4qpZwvpZyfn+9utsuB1vDpswyV3q7wtvf0KSHQZukQi4L3ezaWQksl7HCs6lZhddqh6rF3NEJS\nhKLQVG7tf31kDR5MOhp8ZvVQikLpKkDCsdeq5/WHg6Wg3UcZkDDI7qPy1SrdtaVq8PY51LRZg8e2\nIbxODhV9L6Zbk0l7h8daOCJEoT+SkpKoq6sbmDB4IhWFXuU60sTE+c9diCJSSurq6khKSoKWCvVi\n6Ur/jcrXqMdQotDZZFkKGeFbSM2WKFRuiKzRg4n9Ow2lKBxYrn7nCaeqG/awsBSs3y3JEoXBnNFc\nvV09ttcO3j4Hk6qt8M69oYs5alE4XL+DG9ol6s0oGx5RGBHzFIqKiigrK2NArqWOBmWKxzZAdRjC\n0FqtHnWf1NmsfszGOJ9LKYokJSVRVFQEWz9TL9TvVqOh1Fz1XPv822qUSyEhJXAnHY2QORbiky0f\nfT9IqSyF2ETlvrEfbyhpsrV1IKLQsB9e+Apc/RjkTg7/cwdWwJi56lzmTDx8YgqxCRCXqNxHgxVj\nkRKqLZdL22HaoW57HZY/CKfdAWkF7tvotg/Gd2irVfd2tBMsvJaCNfdkmILN0UxJfQY4G8gTQpQB\nPwHiAaSUjwghRgOrgQzAI4T4DjBTShnxbKr4+HgmTpw4sIY+9yWV4hibAPce9LcCmsrVRRcb73vt\noZshbwpc+5R6vuZJeOcOuHMLZBYNrA0DobnC93/ZKpi2UN3QZashIU0FHptKIX9a4Gc7m2DULIhP\nCs991Nmksm6mLoSdb6u4wjGfC/0ZKWHvh1A0X41kw6GnAxCqXW7YBcx5s0uprL1gnwX49AHlXitd\nGb4o9HYp6+vEb6jn2cWw+4PwPhsprdXw4lfhqr9CxpjQ23a1qHgCKLGyXw+HQlMZdFvxiqG0xiJB\n+95bq0KIwiBaCi/crFJ/oz1pUd+L+rcfJkshmtlH10spx0gp46WURVLKx6SUj0gpH7HeP2i9niGl\nzLL+H/rptS1W2YK+bv+RaGczPDhfdfp22utV1o4mxRoxR3ID1e1WweAXboanvqCqlkbc7oNqhChi\nocxyITWXQ1u16rwhuAsp0kCzdh1Nu0g9hhNXWPko/P1y2PBs/9tqnr4GXv1m8PebylQGUHyq+h3s\nbHkZ7p8a3I3SVgfr/qn+b4mgA61Yr/zr49W8E7InqmvGfsOu+T/4+Pfh7zMYpZ/Bvo98LsBQdDar\neAJYKamD5D6qtgVmD1fXi10UgjGYMYXGA5GtmdxarVK4I0Wnig+zpTAiYgqHRHOFGv2B/2zVyg3q\nR6nZ4XtNSpWplOImCkGzb/1Z/mf40zyVNrp7Cex6F/Z/HHm7WyogcxyMnq0sBfC5jmZ9Xj027g/8\nnKdP+aOTslSn0tcFPZ2hj6WDzPkzIGcSVPYjCruXwNv3qP/DnQEspeqASxarfG3XdhyArHHKdeUU\n4YOboaspeEex6q8qcBebEFn9Ij0/YdxJ6lFfKw22c/vpAypjx8nml+HJS/3KrIdEn+dwBhhOS2Gw\nYgrVVgpnTHz413RnMzxx8dAlIWhRCBUI15bkYAhbR4O678Nl9ePw9Bd9v2e4dDapQZ7uU0aapXBE\n4OlTN2zxGep5nW3NYt3x2c3yrhYVaLZbCvr/cG7k3i41opxwGnxrNdy1TY18d7wdedubK5WZWXSi\nEgNPnxphxsTDMecp/7/b6EZbBtpSgP4nsOl01MyxyrdeESLYXLdbWUD50yBncvglKdrrVDu6muFg\nkP03liohTHERBS0G7Q2Bn+tuV5bL1IWqTS2RiMIKyD3GN1ktx3JT6mBzc6USPreA/f5P1Mj/iYvC\ny/vX5zlsUdCWwiCmpNZsV8H0jMLw/fF7lqjvGi23mhPdQYe0FAYpptDXo65Jt+uqv2Pvei+yY+kE\nEO1uNZbCMNBarVYfG3McJKT7i4Ie9TTb1F5fjAO1FLa8otw7Z3xXxSUSUmDS2bDzrciXxWw5qMzM\ncSeq+EH1ViUKo2erAHLWOHdR0KOspExlLUD/LqSmchVoSxsNhXPViN3t+/Z0wjPXq22vfwYKZoSf\nvmkXj70fBmlHmfpebqKgO3q3Ed2GZ9T2p35bCWlzBCO4irVQtMD33GspWN9r/yfq0U1YO5sgMVN1\nEk9c1H/WUkSWQpPKPAIVQ+rtGJy89uqt6ndLzQt/lL1nqXocjKysJb+GlxeF3sbrPqp2f9/jsdou\n1PVwKOdFH6urKbgF60QH/UsidCF1Nqr7Mt6aJGkshWFA+5YzxkLuJIf7yMVS0B2hn6WQbb3Xz40s\nJax4GPKmwuRzfa9PvVB13jXbw2+3xwOtlijoDuvACiVkY09Qz7PG+7s4NFoAkrJ8nUp/aanN5epY\nsXHKUgDffAg7Zaugdgdc8lvVeeZMVB1FODelFoXEDNj7UeD73e3qRs8sCiIK2lJwiIKnT2WqFM7z\npZSG6z6SUh1HpwiCOnZCmq8D3Ge1tbczMDakF8H58qvq/ycvDe2q09faQNxHEHxkufhH8O+7+t+n\np0+5SwtmuJ/jYOy2anYNRlbW5pdg0wuhYwFeUQjilutoUGueZBerx44IRvnBjuX8P+RnLFHYszSy\neGFnkyUK+vc0ojD06M4hY4xyEWhR6GxW/yekqZG9nsPgZinExqkfsj+fY+lnSmhOutW/HosOCjsn\noYWivVa5sTIK1YWfmg/rn1ZZI3ZRcHUfWRes3X3UXzpjU5kSTlBWFbjHFbSwjT9ZPeZMsiZBhRHY\nrd8DCJh9lfLjO28m7X7JHG91WI7zrS0FZ0e2/1O171O/pc57RqH6TcMZ9fW0q/OszxOofWRP9FlA\n+2zxID3L2Pu8WX127Dy4+m8qkWFniN9ZWzDhuDzsohDfjyhseik8V0bDPiVuBTNUXa9wgrQN+5QY\nxMRB/b7+tw9FZ5OqbSU9wUfZHk//loIOMhfMUI+HElewX2fOe3z3Elj9ROBnOhqU+7a7FQ58Gv6x\nOpvUYM1rKRj30dDTbLcUjlE3bW8XHNyoXj/mPPXodU3oDjXbfz/hjKpWPKw6iOOu9389Y4wafe+M\nIK6g250+WnVSRQuUmwP8RaG9NjAAqb9Dkl0U+nEfNVeoeAIoMckudg8q1uxQI32dPZFt+d/DcSHV\n71HxgmM+p24GZwaOzgzLGqdEubvFJ9a93b4b1nnjajHRFk7GGNXphPJHa+znyk72BNUZ6njCKKsI\ncJfjPNozhCafq6yU9c+4H8vTF76lIKW1b20pWD5ot2Bzc6US5eaK/i02HWQumOEezHdjzzL1OP0S\nFRMZSCadxn5NBRPP7hbfyofBfkMtCvnTreeHIAr268k5EFn1N1jqsn5LZ6NyC8cmQMm7ERzLuI+G\nn5YKqwR2ngpASo+62fXFOe0S9ei9WV3cR9C/KDSVqQk3877snrM/daHKnbdfvB0hRu9apPR0eO1C\nSkiH3Cnq/6wJ6tE5OU1bBUmZ4YmClGoEqy0FUB1sMEshf5rPEtJB2XCCzfV71PYTTgOEzy2j0aKg\nA83g+z3snYPzxtUdRKoVKNbnLJxgs/1c2dFuMd3GaRdb2zvccF3NPhddTCwcd60asbuNcFurVHwL\n0f/ItrdLzcS3B5rBfWSpBwueHmUhhULPZM6frs5xb0f/WU17lqpY09SF6v5pCmMyZDB0W2dcBrs+\ncBcYbSUkZg6OpbD55dBZQqEshbYa9ZozHtjRqCzS4tMjiysEuI+MpTD0NFeqUW1MjLIUQAWbK9er\nTrDQGl1qUdAXRaSWwse/ByQs+Ib7+9MWqvdLFqtsh3/fCf8zMXg2h1cULF/3uBPVY+Fc9V1AWQoQ\n6ELqsLmPdKcSKvuovV65FOyiUDhX7dfZAdfu9J8sl1GkRDccX3P9XuVuSslRa2I7g82NpSpdL31M\n4NwQe8qn88Ztr1WmvB5V64lB4Uz2smdq2ckuVm6xTS+qc1h8mnrdeR47m/0F5bjrVce/6cXAY+mO\nKXdy/0kL9mJ4ENpSsFe17S9FsnqrGkwkpKqBEoQeZXs8sHeZGhVHYhUGo2KdOv7cG5VF4JaqrUUh\nf5q18qFLx6nbrK/FYN+hfA28eAssC7FaYyhLoa1GzW+yn3cpVRuTs2HKBeqeCPec6Oyj2ASVrGEs\nhWGgudzXSeROUo91u5SlMGauUnvwuSDa69UIxVnHPzkneMra9jeUmbngG8rt4MaYuaqz2/QCPHW1\nynNOSIO3f+ju+26uBASkWevzFh6vRhd6ghXYRMERbO5sUh11fIq6+UVsaEvBno6qKZynHu0dTnu9\nGu3m2UQhNk61oz9LQeeB51i/wcQzleVkvymaStXvERsXKAo64Bif4nLj1qpMGm29aEvBLgrd7ari\n7LbXHe0K5j6yOsBd76rgtR4k2C0Fj0d1Wlp4QXVShfNgg//aG6o91nkefazyRYcKSNuL4YFvZOkm\nChVrfe/3N4qv3gYFM9X/4UzKrNqk3p90ti1VNwJRcI6wy9ep+MvEs1T5aLdUbbsogLsLSWce5U0N\n/R0+/oN63P5G8Ppl7fVqXxA44GitCXy9u1UJf3KWEgUIL57T06EGGkmZ6lqNTzGiEHXq98Inf/Q3\nSVsqff7v5Gx1I1SuV8JQOFeNxBIz/S2FlOzAfafkuF94DfvhX/+hgrMX/Dx424RQF9DuD1Rg9MqH\n4YqHVNnftU8Gbt9SaZXfsMQpIRVu+xhOv9O3TWqB+1wFPZtZCPXX36xmPbrMsJXwGHuCGsnomdSg\nRkTg8+Nqcib1P1LS79tFoa/Lv9hfU5lyHUFwSyF/uruJn5rne56Sq0Zi9uB39TZ1Tg9u9v+sN1PL\n4T7SaanSo1wEbhZXdwsgfe4jzXHXw8FNgcfS19iYY/2/mxv2YngQPK9dSiXcU863jhHCUujtVkFe\n7XLR5yxUO3Qq6qSz1QAlLjn8tNSnr4M3vut73larUp0L54VO1daioNvp5kJqq1G/c3yy+m3cvkPt\nLjUIGDVHva8nKTrpaFD3mnMyX0+HezkQ+0Aid7K6psNxITmvtfhk4z6KOgc3wbv3+fyWUqob0e4W\nyT3GGp1IW2Cy0HczOUtcaLz+V9uP2NutTFMp4YtPqsJloTjhK+qYX3kN5t6g/KoTToclvwqML9jF\nzNv2yf7F72Ji3Ocq6LLZmv4qpervbrcUEtOgYJZ/p60zj5y1lrT/PdQ8DG1JaFEYf4qyYOxxhcZS\n9X3AXRRErDq2m4mfaiu3HhOj3G72tFRdc9/ZeXgztRwDgcxxvuKHdlGwn8dOx2heM/tq1cFscASc\nm8rV6DDHqskUyg8e1H3k6ETq96jvMPlcVQoj1AS6ul0q0yoSS2HPUiXEGWOsrKzi8F0lZSvVLHDd\nyWurc6xlhU5dqK5de9kN8P2+evDhZinYf/OUXHf30acPqMHBtX9XVsm2f7u3s8O651Ny/AccOm5h\nbxMEXjNTLlCu0P6qBjit0vhkYylEnQmW31enEHY2KSW2Fx7LmeyrIVNoFwW7peAmCjm+9zUf/Vb5\nLK940NfZhWLsCXDrMuWOAHWTXfhLdcF95Fi+uuWgz7UVCre0VD1BRuNmKdg78KYy1YmlOgqPjVug\niu9ps7tmh+rU9Ghekz3RmhEaonPRHYkegSdlqM5h2+tq/329Spx0wUHn3JDWg2o055aq2lbrLwqg\nXEj2QLPueJxWhj4vzo49LkG1JTFDuXuSXCwF52hek5qr5qZsesHfNdhspf2GM0K3L8UJtsCkw33k\n7WhPUO0N5T7SwlhgdbZaFIL543s6Yf9yNaLXhFtBtrdLfT8dlwFr3ovwpTxPtZaudWYh6c4zlPtI\nuwzBfRJey0ElynNvUPfm5PPUteY2cGm34gPJOf7XVqtNFNzmMug4VNECFZPr77zY5w+B5T4ylkJ0\nSc1VoyAtCrpTsHeuunJmeqGv+mK4lgL438h7l6l6OTOvGHibC+eqC3fFI/4T0Zor/CdUBSNrfGBM\noaPRP3DqFAVdm0mnezZXKOGMcVwqRScq81lbCDXblQ/XuZ0WxFAjyPo96pzbLZ1Tvqn2uf6fqtOX\nfT7BiY1XN4/dUkgbpcS5t8M3wpLSv4PQZIzxjyloUXAKSkejyuhyWwt68rkw5wsqqyg2XrlO7Ocx\nmKUAqjZVa5Uv9RmUpZA51hbgDeU+si3FCb7z5rQUKtaqduXPUPt2CzRLqTrExT9WcSydvZaUqeYe\nBLNYDm5U51qXiAE1AOjPKgR/QdY1oyrWquvHmxBQqARi5zv+n+1oUO1MH6OstaCWgnUe3eZbrHhY\nWUWnWmujz7hMibLbhEw9EEzJ8e/8/SyFIO4jsM2A3xe4bzvOpAZjKQwRxaerSWR9Pb6OPt1FFLSV\nAGqE1Vpt5cI3BLEUXEShbpcv0HUonPUDlU6og6A9nepCTQ/TUmivgy7b+r16gozGKQp7l6lOWq/x\n3FzuH0/Q6Iwn7UKq2REYT4Dw0lJ1OqqdmVcqUf3gF75UySybFWLP+GqpUp2Etw6V1bl3t6mOK8Uh\nCumW9ac7Ly1sbpaCM56gueyPcKmtMmpSRhBLwRGkBt/kvrLVvtf0eQ7HbeMUhXgdU3BaCmtUjCI2\nzrIUHO6jlip45jp47iY1Gv7Sv3ylx4UInVWnC0WOmul7LWeiGt1qP7+U8NrtgVl02nU35QIVwzu4\nSVk12nWkGX+qir3YRUZn9sTEKgswHPeRXdh6OlQix8wrfPf71AuV+9GZaADWQDBb/dkHDfb03lDu\no2CiUFsCv53hK63jTH82gea6EAfkAAAgAElEQVQhYsJp6qKtWOc/m1mj01ILj/e9llEIWGsDdzX3\nYylYF0dns7owI1nIJRjZE5S47LFKCehMm7AsBSvbya8kuMNSSMz078z0qHnlo9Zny9xdVTmT1Pcu\nW6W+b3O5+9oNWRMAEdp8dhMFIeDCX6mb/p0fqtcyx/ve9xOFSkgfFejGc85R0GSMUWLR2ahGdl5L\n0JFB5jxXoUjMcI8pON1HoNxE6WN81W37enwuweQsNQIOGVPQbi1rVB2XoEb19uyjvh6o3OibzJhR\n5D87H2Dpr9Ss3At+CYuWKZegnVCzmmt3qkQGfY1BYF2oyg2w9u+B64hrS+G0O5Rff9l/q7YVOkQh\nc6wSOvuM+44G32+SNiqwUmpvtxJz/ZunWjEFLSxVW9T1Pvtq2/fMgYlnqHVV7AKk00u9loLdfWSJ\nQnyK/+tO91FKrhJtZ8mZ/Z+qZAcdhA4n0Nx4wH+AFyWOPlEA5ULy5vrbRKFgpjIpj7vO95ruEKu2\nqEdn0BECR6j1lvprkTlUJp8L+z5RVoKbmAXDOVfB4wltKXS1KndT1ni1Tm/Zav/ZzHaEUC6k0pXB\nM49AjTwzxgZ3H3W1qA7BLe5SNB/mfFHVUwL/dmhR6OtRHWja6MDfQfvDA0RBp6VW+ka8OZMjsxSc\nJGX4l7nQHZmb+0gI9d3KLUuhpRKQ6vvFxFqj0n4shbgkJQaahFR/91H1NiV8uqPV8Rh7BlL5WhXD\nOvVb7i6yULOaa3eq69u+KJVzroIeeTsnUOp7r2AmTL/Ut519MAa+JBC7q09bCqBEwWkp6Pba3Uee\nHt/AR9/Ho2b5f27GZcq6t5fK72lXcY/kHF9MQYtGW61yLaaPDnQfiVjl4gJfAN5pKeiSOvutMhgB\nloKL++jBBbD010Sbo0sU0vJVx7XvY3VzpOT5ZwXFxMIFv/B1puC7MKusFEI395Ez8KlNwpxBsBQA\nJp2jbvDSzwJnM4fCO6vZEgVdIsAZaO5uVUFPfUOcc6+6qJf8Ut1Qbu4jUCPLuhJfOp+bpQDKCgjm\nPnKmozo57yeqA0zJ9Z8NroPKesSWPjrQ9eK1FFzcR6BGarq0Q/Fp6jzYU5admVqhSAzmPnIRBVAB\nyPo9aiTuLbdineeUvNCTxux1jzTOhXa8ZU+0KFjXsY4r9HYr4dApsG44XS92aneqSr92ssYrK6fB\nKQqOZIfmCvWbJmfD8Tep12Li1KRFOxmONoOLKDhSUp3Wof7t9fms3qrOVVax/+emXwoI2G5zIenB\nhbYUPD3qGgE1kEnLDwxA21O+NdnFgbE93UccWG5ZJI0q/qP7I2eguadDBayjvSQoR5sogC+u0Hgg\nvNG2HlXqvHI3SyE2zj/wWbcbEIEukYFSfLrKANr9QeBs5lCkFaibT1+Q9tnMGnvmjO4gixaofHrt\nC3azFEBZCqCChU5Xgp3s4uDuI2c6qpOsccqNdMIt/q/ruSEtNnea033UHsxS0LOaK1U8ISFNZRHZ\nPwuRWwpO91FMvDr/bujSJOWrbcX+rPPszKLqaoHfzVSl1/W+naKQ4FhToXytuib1edVBen2smu2q\nkxsdShSCiFNvlxr5OmNmcQlK2Br2qQFG7Q7VhqYyf7eMTqkWQmUvZRT5loe1o89HczBRKFCds72m\nk1MUUhzZXFVb1BwHZ0JE+mjlqq3aajuWrYJBgBVqxS1Sch3uo8bAPkJbCvZzUFeiLIq2Git12HGt\nOS2FYCV2osDRJwoTrBHhvk/85ygEIylTmYkHN6nnwZTafnHU71bmui5sdagkpqnA7u4P/EdZ/aEr\neuq2O9PewL/+UbW16E92MZxoq2kf7DyNnacu7JrtatTo5oIA1TG11QRWEQWfKGSHENAFX4Pzfuz/\nWkquGjnpz6fb3UeWXzeopWCJQkulEsL8ae7rYkQaU3BaCkkZ/iNGO2PmWkuprvJ1evo8pzpG6NXb\n1Dbv/9xaOa8l0C3lHFlWrlcJE/r4XpeZJQo680mngLqRkqvOgXNWff0eZXG6JVJkT1DW37bX1PMT\nblZWrl1cdHkZUNb5dU/B5X8K3FfaaGV56PNjLyEB6jf39DrmDzgGAqm21FoplSjYg+N+bS/2H9Hb\nO2LngKNVi4LDUuhocC+g2NPuux77etU50hWS93/qK3GhcQaa3So0R4mjTxSKT1ePfV2BE8CCkVGo\nZltCcKW2z2qu2zU4QWY7k89RN3LVZl911HCYtlCtT9BW6182W+MnClYHGRML+VN9OeiZQdxHCak+\n32ww1xHYMpBcrIWGvermCuZmCYbuxKstH3HaaDVSTUizBZpr1XOnOMclqs83l6vMpvwZgTd9X68a\nPIRrKbgFmt3iCZqEFN9Sqk3lauChz0FKnr+fWrv16neroK2b+ygh1RdollJZq/ZOOz5Z7VdbCpUb\nlRsllItTi6kz1qJjSE73EfjmKmx7XVlDehnTJpsLqaXS30ovPN5dnGLj1O+q3Ufdbcq6sVsK4B9X\n0B2vvj68lkKt2q6j3lfV1onT92/viINZCsHcR879gi/Y3HRAfY9pF6l2HlgeOH/IGWg2lkIUSSvw\n3SzhWArgn30TylKwu48GK56gmWQtzLNnWXjxBM3sq1WO/7bX3Gv5OC2FAtso6vyfwWnf8d1gbujU\nVLcgs0a7MNxcSLoQXqToNlVtAYRvZGi/SZ0lLuxkFKrPtlUrd4LzpnezqkKRlKF8+npUrddSCEXR\nAihbo7LDAoLo9T63SO1OlaWTOwU++p21olsIS6G1Wgma8xq0z1U4uFGJktONYidYeqwWBbdEiuyJ\n6rxXblDBW51GrOMKUrrPyA9G5lifpeAsSKlrfzlFISbed+7tMQUdFywIYilkTbBSuC2L1ptJZLcU\nGtRv3F5nTZjMUb+7nrEczH0EPsGptYLMeVPU7H1tKThFwdOrEins391YClFCWwvhxBTAJx4x8b6s\nAif6Rm6vV6o/2JZC4Vyrg5LhxRM0o2arzmTzy+6loHXn0rBPpbvqmjKgRm/n/1doq0THFUJZCtkT\nAQFbHSl/VVtULn2ozwbDKwpb/etApWT7WwrOeIImvdC3ZkPB9EBLIVjZ7GA46x91Nvdv/RQtUMF/\npyszNU8JuW5DbYnqgM+4SxWhq94auO+EFJ+loF1qzmswc5yyFDwe5VIMFU+A4LOaa0tUHCDR5V7Q\nHSAoUdCxDJ2B1NFgVd0Nc2CTYRcFWycNNlGwBZv1b66v2YRU5RJtr/PFC5yZR8626xG9dkM6Ywrt\ndYD0uY/Atp6Hi/tIJ65oUdCZR7nHqDkrDXvV4CjJ4T4Cn9CPBEtBCPG4EKJaCLE5yPtCCPGAEGKX\nEGKjEGKe23ZRwSsKEVoKKTnBO0g9ucX+gw8mMbEw6Sz/9oSDsFYz2/exzw3h5j4q/Uw9BhtFBWP6\nJcqamHxe8G2SMuDM78PmF32LkrRUwT+vUcc/6+7Ijgm+Dqu5zNc56Ne92UchREEvtgPqOwdYCi6u\ntlA4S124jead6GBzV1OgpQC+71G7Q1m3c75ozdWQLu6jNF+gWadEOy2wjLFKFBr2KksiVOYR2Epu\nOEXBJfNIo12Fo+ao4ydnqbkweq5MJIkSus16omGHrZMG3+9uL53uZh2mWgHz6q1W6fUgHatzRN9R\nr85rXILvmB31/sFs+3WjU76d10x8snKDNVr7rdulBCAlV03Qg0DL0rnQzgixFJ4EFoZ4/yJgivW3\nCHg4im3xZ8blcMWfVTXOcPCuOhbiB9FF8XRQd7DdR+Bb2zlc01sz6ypAqnovIkb5rzX6QtRppXZL\nIRwS05Q14TZqtHPOD1Wd/GW/gc/+ombSdtTD9c8Gz24Khf3msHcwTvdRMNeXdsElZqrzmZCiAvhe\nSyFC95GzKF447qOcSb7Oxp72axcFe6ZPbDyc9m3reM6U1BRfSmrdbpXi6cwGyyyyLBOr0GC4loLd\nfSSlshSCzdbPmaQy0WZd6Xsta5zPUogkpRqsCWztVnl1hygkpqm4iN1SaHcZCOjU2qrNoQc9WhR0\nsNle1iY2Tl0r7fW+2cy63hao66arGZDuSSDZxT4LpM6y/IRQwqytAj9RcFoKDeq79ldYcxCImihI\nKT8E6kNscgXwd6lYAWQJISLs7QZIbDwcf6P/xJtQaIsilErri6NslcoqCbZ2wqEw5QJ14djLcIRD\nwXRV1bS9zqppY/vZdedSv0dd9JFYIZEghCoNMflceOv/qVnlV/8t8u+iScryVSq1i4KeeerxuHcQ\nGu06LJjhs/7s62J0ROg+CrAU+gk0g28pVXDErWxuG2emz/E3qfUG7GtngH9Kav1u5bJwZoPphIEd\nbynR6G8A4G2HTRSaK5SVEcxSSMqE/1yuZit7j2ur1hvJ5EuwZU2VB4oCqI7ZGVNw/uapecoyrdkZ\nPPNI7zcxw99SsJfK165Je4aT7hPa62wuR5eBhF7CFZRoa09CbLzvGvDLPnKxFIbASoDhjSmMBexT\nHcus1wIQQiwSQqwWQqyuqalx2yS66AszVBqovoFKV6oLIDY+Ou34wX6f+ysSZn9ePTov2JhYX+dl\n7yCjQWw8XPN3NVHo0t8r19NAiYmx+ZYdlkJnkyUMvaFjCuCrCgr+pQyCrboWDLul4OlTI/JwMqp0\nh5DpiCmA6mi0yy/fEoX4ZFVeXa+RoIlPVZaqx2OVDXGxVLUo7FmqMq76G3XGxlujY5soeGevh4gD\n5U72v/6zxrm4j8IVBT0TuyKwhAQEzmp2K4CYkqdcR31dwTOPQF37WbbOu6PB3zugrVBtmTjdR27t\n02QX+4StuRzybO5lLfCulkKHb//hpKEPAkdEoFlK+aiUcr6Ucn5+fpCbPJqEJQrWxVEfhcwjOwPt\ntGddpR7dRr76tUhdRwMhMR2u+yfMv6X/bftDC3G6PaZg/Q61JeoxmCjoTjjf9p3tRc8iDTTr7bpa\nfNkr4Xx22kUqEWCUbTav3W2jv0d/MaoEm7uhbo97ooMWhd7O/uMJGuecCd2eSIo9Zo1XFlRHo+rc\nU3LDd4N4Z2KXqQ41Ltk/xTjdJgrdber7u8UUpFXivb+YWfYEW6DZMTrXg4a2GpUNlpTpH2gOtlIf\nKFGQHpU9CP6/p17O1V640WsptPv2fxRYCuWAvfh+kfXa4UdSlrqwQ6Vd2n3Xgx1kHgxyJ8O4k93d\nWl5RiDDIPNx4RcE26tQjN10vKVhKav50uPh+/zpXTktBL1saDvbsI+dymaEYPQduX61KJmjik9XI\nv71Ojcwzx/mX+HBDt7N+j4otuA1M0kYptxH0H0/QOGc11+5U38se3O8P72zqUhUUjiQmljZKuWP1\nKNs5MLNbCsEKIOrrRC/EFAo9gU1K3wI7Gm0paBeVEErcEtKU2zHYokx6v+BbmtNPFM6Aa//pb/05\n3UfByvZHgSBTUIeE14BvCSGeBU4CmqSUlf18ZngQAr61xndDueEnClG0FA6Fm170+eHt2N1HRxIp\nLu4j/VpNP6IgBJz4Df/X7EHqjkbfernhoGMznU2hK6SGi86iqt0R3H9vR4uGTnTIdZn7EROr3GZN\nB8K3FFJy/Utu68yjSCxW+1yFlorIRCEmVm3fXKEssABRKFDn/MAKX+qqW0wBVLv7s1Cyi5Ul1VwR\nOOdAr6nQWu1/XSVbE1dDuY900F+XjrGLthAw41L/7Z2B5o6hcx9FTRSEEM8AZwN5Qogy4CdAPICU\n8hHgTeBiYBfQDgyCPyGK2CtSumE3GQ9XUXBmrGiG0n00mIRyH3lFIQJ3o77ppXRPLQxFfJJyKXQ1\nB1+xLRJSc9WItLYE5p3a//ZOUQg2ITBzrBKFUL51Zzsq1/ue15b4UqPDRZc8byxVgeZQpTVcP2+l\n0nr6XCaGWSmwj1/oe82Z7qrdMuFYwnpEX7kBkP4um+Qc9fs6J9/pAHQo91H6GHV96HUzEvqxQO2W\ngqdP7XuI3EdREwUp5fX9vC+Bb0br+EOOLorX2RjdmEI0SMtXI8hgo+rDlYxCdaPZlwpNdsQUQs3G\ndpKcY00aawosOxAOutRFfxVSwyElV5Wi6GkPz1LQC+1UbVYWrX3tCTujZql9hts2bbFIqUbqLRXh\ntcdOap6KBdTvUUIXyYx8UL9z5UZrVrfj3pp1lRKG9jp13mNiA11j+roOlXmk0SN6vQqb3WWjO+W6\nXf7CpieudjaqdFy3mmcxMWrfdSXhDRrtlkJnEyrV9QgXhaOSlFz1IwarFXS4cs6P4OT/HO5WRM5J\ntyk/rN2K0zdu0wE1qowkC8weNHSuOxEOevU171KcEYqKX1vyfPnw4QR19cjz4EY12g1WnPDCX0Ff\nt/t7wdrR1w2bX/ItZRvpioJCKBdS2SoinpEPKiV8x1tKpJPn+78XEwNFJ4T+fN4UZSVMuaD/Y+nZ\nx1oU/CwFy0rp7Qx0H9Xv9S11G8y1lm2JQlgib7MU7CW8hwAjCoNJSq7qhMKd/3C4kD7K3wVzpJCc\n5VtZTJOQpgLEnp7IXEfgX2W1ozF4KfBgBFgKhyIKNgsnnE5Yjyw7m1RCQTDiEiObAKUDyi99TZ3X\n8acEzpEIh8xxaqlXiHwuTMZY1RG3DnA9geRsNXciHOKTlCWj16NwsxTA3zrVCQpuJS7saNdUOIko\ncTZR8NZ8MqJw5HHqt3wFrAzDgxDqJm2tImBt5v5wWgqRxBTAZik0+Z4PFF3yOSnTVw00FPbspIEU\nGAzGjEuh709KmMbMDVzzIFyyxql5IxD5jHz7HI6hCLZmT/DN8LdPXrN3yvYBR0qu+s3b60K3LxJR\niI1T7jI9mxuMpXBEMvOK4W6BAdTN21oVeYzEPhFpoDGF1t1KGGIjHJE70ZZC3tTwMn3sqbODmeiQ\nkArzvnzo+8m0ZZ9HbCnY3LFDIgrFPlFwZh9p7CnE+rqp3xs6q2vcycryCjfQrhfa8RbDM5PXDIaB\noTvUSN1H3nhEqRrVRhxTyPRZCodiJYDPygnXfx8tS2Gw0K64mPjIgv/gLyJD0THqtooY/7iQ/dh+\nloJ13bRUhL5mxi2A7+0Mz/IDXzn0ISyGB0YUDCMRbfJHKgpJmYDwrfsQqftIxxTCqXvUH3ZLIRzs\nonA4pkTruQp6Gc5ISCvwzREaKktBH8teJ0zHqyAwpqCJ9JoJhd1ScApUFDGiYBh5aHM+UvdRTKy6\nqfUKcZG6j5IyVM2jzsZDtxTypqhJecVnhLd9bLzqsGLi/V01hwu6TeEWwrOjJ93BEIuCY2Su41UI\nf2sn2SVDaTDQS3LqiWuhFkQaRExMwTDySBmgKICVXmgtUhOp+0hPDmyuPPRsrtQ8+N6OyD6TkKJG\nsIdj9lv6aDXajzTIrNFL4g5VoBnc3TXJOcq1aE/5tW8X6TUTCr0k5xCWuABjKRhGIl5LYQDFE1Ny\nfJU8BxJoBhWTOFT30UBISDs8XUeghOqEW9RqbAPBu6bJEIhC2miVKOB2rJQcf9cROCyFKLiPhrAY\nHhhLwTAS0bn1AxmVHsoNrl1G3a2H7j4aCOf80H85zMONS+4f+GfzpqrfJtwChYdCTAxMOhvGzg98\n7+T/8C17qklIVSLS1zX47qPOSujyDOmEWCMKhpHHzCtUpzyQUfOhuALs1sEQBQX9OP6moT/mUHHa\nHer7RXO9Dzs3Pu/+upulo2MNLZVRcB91KBEaPaf/7QcJ4z4yjDzik9Q6BQPBbilE6gKyu5uGw1IY\nycQnH97lY/R1M6juoxRf9tEQuo+MKBgMdnQ6a0J68PpBwfCzFIwoHFXoTntQ3UfJShB6O4Zs4hoY\nUTAY/DmUEZ/dOjiUukeGIw8tCoPuPmrz3/8QYETBYLDjvbkH0KnbrQPjPjq6SMlT5cv7W3clEuxB\n9SFMSTWBZoPBTvIhjPjik1UuvqfXuI+ONk7+T5h8zuDu074ug0lJNRiGiUOxFIRQE9g6GoylcLSR\nd4z6G0yGyVIw7iODwc6hZpFoC8FYCoZDZZgsBSMKBoOdQw0YagvBBJoNh4qxFAyGw4D4ZDjuejjm\nvIF9Xk9aM5aC4VDRlkJ8ysAXNxoAJqZgMDj5/CMD/2xShlpKcTCzUAxHJ1oUhtBKAGMpGAyDS3LO\nkE40MoxgtPsoZWivp6iKghBioRBihxBilxDibpf3Jwgh3hdCbBRCLBVCHMbz2A2GMDjjLrj6r8Pd\nCsNIYKRZCkKIWOAh4CJgJnC9EGKmY7P7gb9LKY8Ffgb8OlrtMRiGhNzJUHz6cLfCMBLQlsIQW57R\ntBROBHZJKfdIKbuBZwHnyvYzgQ+s/5e4vG8wGAxHJ9pSGMJ0VIiuKIwFSm3Py6zX7GwArrL+/zyQ\nLoQIWNVbCLFICLFaCLG6pqYmKo01GAyGwwqvpTByRCEcvgecJYRYB5wFlAN9zo2klI9KKedLKefn\n5w9gNS2DwWA40kjMgLEnwLiThvSw0UxJLQfsK4gXWa95kVJWYFkKQog04GopZWMU22QwGAxHBrFx\n8I0P+t9ukImmpbAKmCKEmCiESACuA16zbyCEyBNC6DbcAzwexfYYDAaDoR+iJgpSyl7gW8A7wDbg\neSnlFiHEz4QQl1ubnQ3sEELsBEYBv4xWewwGg8HQP0JKOdxtiIj58+fL1atXD3czDAaD4YhCCLFG\nSjm/v+3CshSEEHcIITKE4jEhxFohxAWH3kyDwWAwHE6E6z76qpSyGbgAyAa+BPwmaq0yGAwGw7AQ\nrigI6/Fi4B9Syi221wwGg8EwQghXFNYIIRajROEdIUQ64IleswwGg8EwHIQ7T+FrwFxgj5SyXQiR\nA9wSvWYZDAaDYTgI11I4BdghpWwUQtwE/Ahoil6zDAaDwTAchCsKDwPtQojjgO8Cu4G/R61VBoPB\nYBgWwhWFXqkmNFwBPCilfAhIj16zDAaDwTAchBtTaBFC3INKRT3DKk0RH71mGQwGg2E4CNdSuBbo\nQs1XOIgqbve/UWuVwWAwGIaFsETBEoJ/AplCiEuBTimliSkYDAbDCCPcMhfXACuBLwLXAJ8JIb4Q\nzYYZDAaDYegJN6ZwL7BASlkNIITIB94DXoxWwwwGg8Ew9IQbU4jRgmBRF8FnDQaDwXCEEK6l8LYQ\n4h3gGev5tcCb0WmSwWAwGIaLsERBSvl9IcTVwGnWS49KKV+JXrMMBoPBMByEvUazlPIl4KUotsVg\nMBgMw0xIURBCtABuS7MJQEopM6LSKoPBYDAMCyFFQUppSlkYDAbDUYTJIDIYDAaDFyMKBoPBYPBi\nRMFgMBgMXqIqCkKIhUKIHUKIXUKIu13eHy+EWCKEWCeE2CiEuDia7TEYDAZDaKImCkKIWOAh4CJg\nJnC9EGKmY7MfAc9LKY8HrgP+HK32GAwGg6F/omkpnAjsklLukVJ2A8+iFumxIwGd1poJVESxPQaD\nwWDoh2iKwlig1Pa8zHrNzk+Bm4QQZaiyGbe77UgIsUgIsVoIsbqmpiYabTUYDAYDwx9ovh54UkpZ\nBFwM/MNa1c0PKeWjUsr5Usr5+fn5Q95Ig8FgOFqIpiiUA+Nsz4us1+x8DXgeQEq5HEgC8qLYJoPB\nYDCEIJqisAqYIoSYKIRIQAWSX3NscwA4D0AIMQMlCsY/ZDAYDMNE1ERBStkLfAt4B9iGyjLaIoT4\nmRDicmuz7wLfEEJsQJXlvllK6VZryWAwGAxDQNhVUgeClPJNHOsuSCnvs/2/FV85boPBYDAMM8Md\naDYYDAbDYYQRBYPBYDB4MaJgMBgMBi9GFAwGg8HgxYiCwWAwGLwYUTAYDAaDFyMKBoPBYPBiRMFg\nMBgMXowoGAwGg8GLEQWDwWAweDGiYDAYDAYvRhQMBoPB4MWIgsFgMBi8GFEwGAwGgxcjCgaDwWDw\nYkTBYDAYDF6MKBgMBoPBixEFg8FgMHgxomAwGAwGL0YUDAaDweDFiILBYDAYvBhRMBgMBoOXqIqC\nEGKhEGKHEGKXEOJul/d/L4RYb/3tFEI0RrM9BoPBYAhNXLR2LISIBR4CzgfKgFVCiNeklFv1NlLK\nO23b3w4cH632GAwGg6F/omkpnAjsklLukVJ2A88CV4TY/nrgmSi2x2AwGAz9EE1RGAuU2p6XWa8F\nIISYAEwEPgjy/iIhxGohxOqamppBb6jBYDAYFIdLoPk64EUpZZ/bm1LKR6WU86WU8/Pz84e4aQaD\nwXD0EE1RKAfG2Z4XWa+5cR3GdWQwGAzDTjRFYRUwRQgxUQiRgOr4X3NuJISYDmQDy6PYFoPBYDCE\nQdREQUrZC3wLeAfYBjwvpdwihPiZEOJy26bXAc9KKWW02mIwGAyG8IhaSiqAlPJN4E3Ha/c5nv80\nmm0wGAwGQ/gcLoFmg8FgMBwGGFEwGAwGgxcjCgaDwWDwYkTBYDAYDF6MKBgMBoPBixEFg8FgMHgx\nomAwGAwGL0YUDAaDweDFiILBYDAYvBxVotDd6xnuJhgMBsNhzVEjCou3HOTkX7/PwabOgPcqGjsw\npZcMBoPhKBKFGWMyaGzv5olP9/q9/nFJLaf+5gPu/ddmIwwO9tS08tcP95jzYjAcRRw1ojAuJ4WL\n5ozh6RUHaOnsAUBKyW/f3UFCXAxPf3aAn/17q2sHWNfaxZce+4zXNlQMdbOHlQeX7OKXb25jX137\ncDfFYDAMEUeNKADceuYkWrp6eXalWiV06c4a1h1o5CeXzeSW04p54pN9/M87O/yEoamjhy89tpKP\nSmr50/slR82ouafPw/vbqgH4ZFftsLbl129u44a/rhjWNhgMRwtHlSgcW5TFKZNyefyTvXT3evjD\nuzspyk7miyeM475LZ3LDSeN5eOlubvjrZyzZXk1rVy+3PLGSkuoWrpxbSEl1KxvLmvz2+cD7Jfxj\nxf5h+kbRY+Xeepo6lEW1fHfdkBxz8ZaDrsd6d1sVn+6uo6KxY0jaYTAczUR1PYXDkUVnTeKWJ1bx\n3Rc2sKGsif+5+lgS4pQ2/uKK2UzKS+VvH+3llidXkZoQS2evh4dumMepx+Ty1uaDvLimjOPGZQGw\npaKJ3727kxgBxxVlcqUutRcAACAASURBVGxRlusxd9e08v62KpIT4khLjGX66AxmjMnw22ZrRTMP\nL9vNd8+fSnFeanRPAvDMygP09nn40inFru+/s+UgSfExnDd9FJ/ursXjkcTECNdtW7t6WX+gkbUH\nGthT08rdF81gdGZSRO3p80j+30sbGZedwuu3n+59vam9hz01bQAs3VHDDSeNj2i/BoMhMo46UTh7\naj7TRqXz+oYKxuek8Pl5Y73vxcQIvn7GJL5yajFvbKzkuVWlXH/SeBbOHg3AwtmjeW1DBfdeMoOk\n+Fj++F4J6UlxJMfH8v9e3Mjrt59OfKy/8eXxSG5/eh1bK5u9r8XGCJ6/9RROmJANqFTZO59bz46q\nFj4qqeHPN8zj1GPyonYOnv7sAD98ZRN5aYmuouDxSBZvqeLMKfmcO72ANzZVsv1gCzMLMwK2XbO/\nnhv/9hmdPb503xOKc/jSyRMiatP60gYa23to7miipbOH9KR4ADaUNQIQI+CD7dVDLgrbKpvJS0sk\nPz1xSI9b09LFVQ9/wp9vOIE5RZlDemzD0c1R5T4CEEKw6MxJAHz7vCkBnThAfGwMVx4/lmcWnczl\nxxV6X//CCUU0dfTw/rZqNpc3sXhrFV87fSI/v3I22w+28OiHewL29eqGcrZWNvO/XziWlT88j8V3\nnsmYzCS+89w6b8D7kWW72VHVwk8vm0l+WiJfenwl/1i+L+T3qGru5I2NlTRb+wiXNzZWcu+/NpGZ\nHE9taxfVzYEpuhvLmzjY3MmFs0Zz6jG5AHy6OzCu0OeR/OhfW8hJSeDvXz2RDT+5gLTEOHZVtUTU\nJoAl22sA8EhYe6DR+/r60kaEgMuPK+STXbV09vRFvO+B0tXbxxcfWc6VD33iep76o7a1i7UHGgZ0\n7DX7Gyit72D5nuGN5xiOPo46UQC4at5YXrztFK62WQnhcOrkPMZkJvHimlL+8N5OMpLi+OrpE7lw\n1mgunjOaP75fwq7qVu/2nT193P/OTuaMzeTqeUUUZCQxdVQ6f7h2LuUNHfzk1S2UVLXw4Ae7uPTY\nMdx82kRe/s9TOXtqPj9+dQtr9tf7Hb/PI/nT+yUs/MOHnPSr9/nm02u55+VNYbf/o5IavvPcOk4Y\nn80fr5sLwJaK5oDt3tlykNgYwXkzChiTmcykvFQ+dfH1P7PyANsqm7n3kpmcOTWfzOR4jilIo8R2\nDsJlyY5qZo/NIDZGsGqv73uvL21kcn4aV8wdS0dPHyv31ofYSyD769r45j/XsmJP5HGRVXsbaO3q\npaKpg688scor4uHQ0tnDdY+u4AsPf8qBAWRvactSu84MhqHiqBQFIQTzi3MQwt1HHozYGMFV88ay\ndGcN722r5utnTCLDcnP89PJZJMfHsugfq9l+UN3Q/1i+n/LGDu65aLqfP35+cQ63nzuFl9eV8+XH\nV5KSGMtPL58FQHpSPA9cfzyJcTG8tt4/BXbZzmp+++5O0hLjuPui6dxymnJzLdle3W/bO7r7+O7z\nG5iUl8ZjNy/wuq62VDQFbPvOloOcPCmHrJQEAE6ZnMtne+ro6fO5iBrbu7l/8Q5OmpjDxXNGe1+f\nUpDGzqrIRKGquZMtFc1cMqeQWYUZrNynOn4pJetLG5k7LouTJ+WSGBfDB7bv2tDWzep9wUXC45F8\n/8WNvLGpkuseXcE9L2/yBs/DYemOahJiY3j4xnmUVLVw21NrwpoV7/FI7nxuPXtr24iNEfzlw91h\nH1OzTYtCrREFw9ByVIrCoXD1vCKkhMzkeG45rdj7ekF6Eg/fNI/mjl4uf/ATHlm2mweX7OKsqfmu\n8YHbzz2GeeOzqGzq5L5LZ5KX5vNZpybGcc60At7afJA+jy8F9pV1FWSnxPP0N07mtrMmc89FM5hS\nkMaP/rWZ9u7ekO1+asV+qlu6+NkVs8hMjic9KZ4JuSkBlsKu6hb21LRx4SxfR3/q5Dzauvv8Mq9+\n9+5Omjt6+Onls/zEdcqoNGpbu2ho6+7/ZFos3aE6+nOm57OgOIf1pY109fZRWt9BfVs3c8dlkZwQ\ny6mTc1myoxopJZ09fXzliZVc++gK6lq7XPf7zKoDrNxbz08vm8miMyfx3KoDnP+7ZWFnMS3bWcNJ\nk3JYOHsMv7n6WD7ZVcd3nlvnJ45u/P69nby3rZr7Lp3JF04YxwuryyJ2P20zloJhmDCiECGT8tP4\n6mkTue/Smd5gqObUyXm8/Z0zOP2YPH7z1naaO3u4+6LprvuJi43hL1+azwPXH8/njw90Y1187Biq\nW7q8I+GWzh4WbznIpccWerOlEuJi+NVVcyhv7OD37+4M2ubWrl4eXrabM6bkcdKkXO/rswozAkTh\nnS1VAFww0ycKp0xWn1luxRXe3lzJUyv2c9PJEwKyqKYUpAOwqyZ8a2HJ9hrGZCYxbVQ6C4pz6O71\nsKmsiXWlyh8/18r2Ond6Afvr2tlT28Z9r25mY1kTfR7J+y6W0sGmTn7z5nZOnZzLV04t5ocXz+C5\nW0+huqWL97ZV9dum8sYOSqpbOWtqPqDiST+6ZAZvbjrIN/+5NqjF8Mq6Mv70wS6unT+OL58ygdvO\nmkSvx8NjH+913d6Npo4eyho6yElNoLa1K+K40dFEc2cPr6wrw+M5OuYPDQVRFQUhxEIhxA4hxC4h\nxN1BtrlGCLFVCLFFCPF0NNszWNx32UyuPqHI9b28tEQe+8p8fnPVHH52xeyATtNOfnoilx9X6OrG\nOm96AYlxMby5qRJQnXVXr4crHQKyoDiH608cz2Mf7+Wnr23hnpc3csez63jdNvv6yU/2Ut/WzV3n\nT/X77KzCTA7Ut/t1Ou9tq+LYoky/lNKc1ARmjMng3W3VfPPptdz21Fqmj84I2B8oSwGgJIQLqbOn\nzzsJsLvXw8e7ajl7WgFCCBYUK7fWyn31rC9tJCk+humjldCcPa0AgO+9sIHnV5fxzXMmU5iZxLtb\n/Tt5KSU/+tdmejwefn3VHO/5nT8hm7y0BDaUBrrMnCzbUWMdM9/72tfPmMRPL5vJ4q1V3PbUGr+g\nt5SSh5fu5s7nNnDSxBx+dqWyoCbkpnLJsYU8tWI/Te3hde7bLStBZ73tPURr4ZV1ZTy36sAh7SMY\npfXt3P/ODhb+4cOI4z1u7K9rY8fB8BMVnv7sAHc+t4EnPt13yMf+/bs7+bhkYIH9vyzbzYW//3BE\nTG6NWkqqECIWeAg4HygDVgkhXpNSbrVtMwW4BzhNStkghCiIVnuGEiEE1514aKmTdhfSfZfN4pV1\nZUzITWHe+MC5EHcvnM66Aw08v7qU1ET1k766voJlO2v43gXTePTDPXxuRgHHj8/2+5xOMd1a0czJ\nk3Kpbe1ifWkj3zkvsLM/dXIuj328l20VzXz3/KncdvZk18ytwsxkUhJiKan2v7GX7KjmrU2VrD3Q\nyK7qVuaNz+K318ylsrGD1q5ezp2ufvrctESOKUhj1d56Gjt6mDM2kzjrOONyUphSkMa6A42cPS2f\nu86fRktnL8+vLqWju4/khFgA3t9WzXvbqvjhxdOZkOub8yGE4NiiLDaWNdIfS3dUMzYrmcn5aX6v\n33zaROLjYrj3lc1c/MePuHjOGD43cxTPrjzAs6tKuey4Qv73C8eSGBfr/cx/nj2Z1zdU8Pfl+7j9\nvCn9Hlu7ji6dM4anPzvAntpW79yYULR19ZIcH+sXvypv7ODulzYRFyO4/Lix3nMUCikl3X0ev+/g\npKm9hzufX88Sy/WXGBfD79/dyTOLTu53/8HYVtnMtX9ZTnpSPB//4JywYn56suN/v72dM6fkMWVU\n+oCO3dnTxwMflDBtVDpv3XFGxPHGj0pq2VHVQk1rFwXpkc3ROdyIpqVwIrBLSrlHStkNPAtc4djm\nG8BDUsoGACll/xHTowjtQvr3xgo+3V3HlXPHul6smSnxvP2dM9n6s4WsuvdzLL/7XL593hReWlvG\nOfcvpbmzlztdRvWzLCtGu5A+2F6NlHDejEBtvvGk8Vw9r4g3vn06twdJ5QU11+OYgjS/LKyKxg5u\neWIVi7dWMT4nhVvPnMSu6lYu/uNH/Pc7O0iIjeHUyT631oLiHFbva2BLRbPXdaT5wglFzBiTwR+v\nPZ7YGMH5M0fR2aOsDVAd2p+W7GJ8TgpfPW1iQPvmjM1kV00rbV3BYzDdvR4+3V3HWdPyXc/3jSdN\n4JGbTmBURhIPL9vNlQ99wrOrSrn93GP447VzSYr370xnjMng3OkFPPHpPjq6+0+p3VrZTG5qAvOL\nc4gR4cUVPB7J5Q9+zA1/W+EX8/ift7fT3eehrbuPxVsP9rsfgBfWlDH/5+9R3RI8DvLrt7axbGcN\nt587hY9/cC53nT+V5Xvq2FTWvxXmxoG6dr78+Epau3opb+xgvyNjS0oZEMvp6fOwal89F88ZTVpi\nHN95bv2Ay+Pvq2tDSth+sIX1pf0PGpxt0wkbkVg5hyvRFIWxQKnteZn1mp2pwFQhxCdCiBVCiIVu\nOxJCLBJCrBZCrK6pqYlScw8/tAvpJ69tQUoCXEfBiIuN4a7zp/L0108mKyWeq+aNZVZh4ASogowk\n8tISvRf0B9uqGZ2RxCyXSWqT8tP47TXHhTUSO6Ygzc99pDOGXrztVB6/eQH3XDyDxXeexYKJOWwo\nbeSkSTleCwfgxInZtHT10t3rYe44f+vm1rMm89YdZ5CZouI5J03MJT0xjnetDm/Fnno2lDay6MxJ\nXgvDznHjMpESNpf7d14Hmzq9Hcqa/SoVVccT3Fg4ezTPLDqZ1fd+jt9dcxz/99UT+e4F04LO+v6P\nsydT39bNi2tKXd+3s62yhRljMkiIi2FcTkpYovDZ3np217SxYk89//3WdgDWHWjg1fUV3HbWZMZm\nJfPKunK/z2wobeTpzwLdSk+t2E9LVy//cmyvWbWvnmdXlfK10ydy1/lTGZuVzPUnjic9MY5HPwqc\nq9Mf1c2d3PTYZ/T0efjzjfMAAlKIH162mzP/ZwldvT5R3VTeRHt3H5ceW8ivr5rDlopm/vh+8Nha\nKOzn2O2chOJgcycNlmvQiMKhEwdMAc4Grgf+KoQIsJOllI9KKedLKefn5we/UUca2oXU2N7D3HFZ\nTIyw/MUpk3P55Afncv8Xjgu6zazCDLZWNNPV28dHJTWcO6MgYtPZyZSCdA42d3pjFR9sr2ZCbgqT\n833tH52ZxP/dsoBHbprHTy6b5ff5BcU53v/nurjL7CTExXD29ALe31ZNn0fy8LLd5KUl8oUgMR9d\nisSeSVXV3MmZ/7uEz/1uGa9vqGDpzmriYgSnhTGrPDs1gavmFYUUEFDxjLnjsvjbx3v9MsrWlzZy\n499WeNf56O3zsKOqhRljlPhOykv1S0vt80hu+8car9tG88q6MtIS47huwTj+9vFe/r2xgl+8sY28\ntES+ec4xXDG3kI9KaqlpUZlaXb19fPvZdfzwlU2U2CYbllS1sLGsidgYwQurywJ85N29Hn748ibG\nZiXznc/5XGHpSfFcf9J43txUSWl9+PMypJR88+m11LZ28cTNC7hw1mjy0xNZ7hCFV9aWU9nU6Y31\ngM91dNLEHC6cNZpr5hfx56W7ueYvy5Wrs7KZtzdX8qs3t3HLEyvZ6jInR7PbsmyvmFvI6xsrIgru\n2/e73YhCSMqBcbbnRdZrdsqA16SUPVLKvcBOlEgYLC4+dgygJtwNhJgYEXT0CkoUdlW38uHOWtq6\n+/ici+soUqYU+ILNHd19fLKrlnOnB4qNEIKFs8dwTIG/374oO4XCTGXFFIZRQ+n8maOoa+vmH8v3\n8eHOGr56enGAC0eTl5bI2KxkNtoshbc3H6S710NcrOD2Z9bx6Id7mF+cTVri4IXchBDceuYk9te1\ns3iLsmo6e/q467n1fLKrzjsbfm9tG929Hm+8Z1J+GntrW73ZNesONPD2loP8/PWtXnHp7OnjrU0H\nWTh7ND+7Yvb/b+/O46uqrgWO/9a9yc08JyQkISSBEEjAMIlhEBTFB4gMFbWi1iq1tXX2+Xzqe/qq\n1vbj59na2lrr01pxqEMVlVqrKA51YBAZFBMEEgMCIRNjAgkZ9vvjnHu8mchAQjB3fT8fPnBPTu49\nOzucdc7ee63D2LRobnx+A59t38ct5wwjPCiABWNSaGwyTvn3JZ+UsL3qMAEu4TGfq/uX1u3E7RJu\nOjuLreXVbGwxHPTYh8VsLa/mnnm5hHqa/3x+OCkdAf7ycUmnfy5vbtrDpyX7uHNODmPSYhAR8jPj\nWFlU5QSk4opqJyHyNZ8FFKuKq8hOjCDOXs7987m5XD89iwOH67n39QJm/e5Drn5mHU9+XMKar/dy\n9TOftXuyL66sISU6hMVTMqitb2r3Lqkt3qAwJi3ayVH6LuvNoPApkCUiGSLiAb4PLGuxz6tYdwmI\nSDzWcFLX7z/7sVkjk/jlglFcOH5Qxzt3Q25yFA1Nhkfe30ZwoItJQ46/5pJ3BdK28kN8UlRJXUOT\nM5HcWT89YwhXT8vs1F3LGdkJBLqF+94oJCIogEs7qLs0KiWq2WTzG1+UMiwxnLdvmsYDF+QxNCGc\ni07t+Z/3OblJpMeF8qj94KLfvrOV4soacpMjeW7NDvbWHHUymb2r1jLiw6itb6LUznN4xy5nXlxZ\n46wwW1FYzqG6BhaMScET4OKPl4wjOjSQEQMjucD+vclKjGBkSiSvrt9FZXUdv1+xjbOGD+DiCWm8\nun435QdraWwyvLp+F2dmJ3D5pHSCA138be23w11FFdU8tGIrM3OTOGtEYqv2JUeHcF5eMs9/uqNT\nK63qG5u4/83NDEsMb/b7PTEzjvJDdc4dknd12fThA1hRWEaNPbS4tmQf+Znf3lWGegK4acYw3rpp\nKu/fcgYPXJDH0p9N4ou7z+GpxRPYvf8It/7t8zZXCBVVVJOZEMaolChykyP56+odnV5JVFB6kPS4\nUMalxbC1rLrZneB3Ua8FBWNMA3At8BZQCLxojPlSRO4Rkbn2bm8BVSJSALwH/Icx5sTUaf6OCHS7\nWHRaWrtXvsfLO3+wbsd+pgyN75HPSY0JJTjQxdayat7dXE6Yx82EjNiOv9HHZRPT+dHpmZ3aNzI4\nkPzMOOobDZfkD3ayzNtzyqAotlcdZv/ho1QcqmNNyV5mjRyI2yUsHJfK2zdPY8GYtoefjofbJSw+\nPZMN3+zniY9LeOzDYi4aP4gHLxrNkfpGlnxSQkHpQTxul7PqKdMecvMuS11RWMakIXEMT4rgoXe3\n0thkeGX9ThIjg8i3c1CSooJZftM0nv9xPm6fu8QFY1L5YtcBbnx+A0fqG7nj3BEsnpJBfVMTT35S\nwodbKyg7WMf5Y1OJCA5k1siBLNu4m9r6Rg4cqeeqp9YSFhTgZN+35arTMzl8tJFrn1vXblKh119X\n76Ck6jC3zxrR7Di9J3rvvMLygjJGpkRy9bQh1NY38XZBGV/s2s+R+kYnh6al9PgwFo5LZWxaDEEB\nbsYNjuW2WcN588s9PNHiTsYYQ1F5NUMSwhERFp2WxuY9h1jfyQnngtKD5CRHkp0UQV1DEyVVXVtC\nXFVdx60vbeTrkyR7vVfnFIwxbxhjhhljhhhj7rO33WWMWWb/2xhjbjbG5BhjRhljnu/N41GtpcWG\nOsMkbV39dYfbJQxJCGdLuRUUTs9KOObyxp5w/thUokICudIny7w9efa8whe7DvDWl3swBmaPGtir\nx+e1cGwqsWEe7n29gPhwD3ecO4JhiRHMyElkycoSPivZx9AB4c7qLm9wKK6sZntVDVvLqzl7RCLX\nn5VFcUUNT68s4f2vKpg3OqXZiTU2zENUSPPgODcvGbdL+GhbJT+YmM6QhHDS48OYmZvEM6u288yq\n7USFBDLdHkK8YFwqh2ob+OemUq5/bj07qg7zp0vHHbMsek5yJL9cMIrVX+9l9kMfsrqdmlMHa+v5\n3YqtTMyMa5YLAtbdUWJkECuLqig/VMu6Hfs4JyeJ8YNjGBgVzLKNu535hAkZbQeFtiyeksGMnER+\n9UZhs4UG5YfqqDna6ATgeaNTCPO4+fXyrzrMXj9YW8/2qsPkJkcxPMm6wOrqZPMDy7fw4tqd3PjC\nBho6+LwToa8nmlUfc7mEHHuooqtDPMeSNSCcVUVVlB6odU4yvWn+mBTW3zmDAZEdz0GMTLFWYn2+\n8wD/3FRKZkIYwxLDO/iunhHicXO5Xa78F/NHOSfun54xhP2H61m7fV+zEuUDIoII87gprqhxho7O\nHpHIzNwkshMjuPcfhTQ0mTaz4ltKiAhi2rAEYkIDucEnX+KqqZkcrG3gncJy5uYlOwE8PzOO1JgQ\n7li6iQ+2VHDPvJGduuNbdFoar/xsEqGeAC5+bBXPr2m9mueR94vYW3OUO2aPaHOuaWJmHKuK9/JO\ngbVMekZOIi6XcF5eMv/aUsGbX+5heFIEsWGeDo/H930fWJiH2yUsXfftnIF3ktkbgMODArjrvBw+\n3lbFrS99fsxs6c2lVgDIGRhJVmI4Lmk92XysYaiC3Qd54dMdjEqJYuM3+3m8C5nvvUWDgmLhuFQW\nnZZGYidOqJ2VlRjBUfuq58zsE5OTeKwJdV9RIYFkxIfx/lflrCrey+yRA497xVVXXDt9KG/dOJUZ\nOd/emY1Ni3GGTXyz4EWEjARrBdKKwjKGJYaTFheKyyVcd9ZQGpsMw5Mijpk57+vXF+Sx7NopzpJe\n72d7M8l9M/VdLuH8sakcqW/kBxMHd+lZFrnJUfz9uilMyUrgv17d1CxT+O8bd/OnD4o4f2xqu8+K\n8CZTPv5hMYNiQ5ys9rl5yTQ0GTbtOugMl3VFVGgg49NjmpWCL7KHbXwTFS86NY1bzhnGK+t3cd8b\nhe2e2Avs5dw5yZEEB7pJjw9zMtIBXtuwi+F3vsnPl31JWYv6V8YY7n29gMiQQJ5ePIGZuUn85u0t\nbLMTPzftOsBtL3/eavl0b/O7h+yo1i48dRAX9vDEqndFUV5q1Al/QE1nnJIaxWt2FdpZPlVeTwS3\nS8hOap3vcd30LNZ8vZrxg5vnZmTGh/NJUSX7D9dz1dRv51lmjxzI7FGlzYoXdiQmzENMG1fXd83J\n5e3CMvJanKR/Mi2TwXGhnOfzXJHOCg8K4OFFY1j4yEp+9uxnvHLNZHbuO8LNL27g1MGx3LdgZLvf\n650rKK6sYfGUDCdo5yZHkpkQRnFFTbeCAlg1yv73ra+oqq4jLjyIovJqwjxuEiOb/55ec+ZQKquP\n8uePvmbf4aOcO2og+ZlxzXJqvImGA+zf8eFJEU4yqLf0SYjHzdOrtvPXNTu4+NRBLDptMNlJESwv\nKGNlcRV3z80lOtTDvfNHsvrBD7jphY0kRwc7dciKK2p48eqJ3Wprd2hQUL0i205ymz68Z+Ypetop\nqdG8tmE3g+NCneGzvjZ5aDzr7zqn1VxAZkKYs5TUd8mwyyX88ZJxPfLZo1Kj2rxqD/UE8L2x3Z90\njwgO5PHLxzP/4Y+5/Ik1VFUfJWtABI//cPwxFzWkxVrLkncfqOUcnzsqEevu5aEVWzmti4sXvLzZ\n8yuLq5hzSjLFlTVk2pPMvkSEu+bkAPDCp9+wdN0uAt3C909N4555Vm0r7ySz93uzEyP556Y9HD7a\nQMHug2zec4hffW8Uk4fE8/B723h29Q6WrNzOqJQoqqrryBoQziX2HVhCRBB3zxvJ9c+tp6SyhhvP\nziLAJTywfAuri6uaFbPsTRoUVK9Ijw/jj5eMZWoHSV19xXtFPOsEDx11pGVAACtXAazJ45YZ3t8F\ng2JDefSycSx6bDXJ0cEsuXJChyvERISpwxJ4d3O58+wPr59MzWTBmJQ273g6Y1RKFOFBAXxSZAWF\novJqxqe3/XN1uYSfz83l9tnDWVuyj6XrdvH0qu1kJYZz8YQ0tuyp5oop6c7+wwdGYAxsKavm6VXb\niQgOYN7oZEI9Ady/8BRunZnNaxt28/K6new5WMuSKyc0y7w/75SBDIgIYkRSJFGhgdTWN/LkJyX8\n4b1tGhTUd9+JWtHTHaMHRXPtmUO5bGLXniXdFzLtTPYzswc0W2H0XTI+PZY3bphCXFhQp0/md87J\n4eYZw1qVKwlwu0iODun2sQS4XZyWEcvKoiqOHG1k1/4jXJRw7OHToAA3k4fGMzEzjqqaOn7xeiGh\nngCONjY1u9P0zn18vK2SN74o5dL8wc2S/OLCg7hySgZXTsmguq6hVYKkN3nPKzjQzeIpmdz/5mY2\nfrO/U4URj5dONCu/FOB2ccu/Zffo5HpvyUoMZ9qwBC7NP77Ku31t6ICILl3dhwUFdGo1WXdMGhrP\n15U1zoRzZkLnSsi4XMJvLhxNbJiH217+HKBZrbBBMaGEetw88n4R9Y3mmImUnc2YvzQ/jcjgAB5+\nb1un9j9eGhSUOskFBbhZcuWEVqXPVfd55xWeWbUdoFWJ9GOJDfPw+0VjMEBwoIuM+G+/1+USshIj\nqK5rYPLQuC69b3siggO5YnIGywvKTkjBPQ0KSim/k51o5Ti8v6UCEbpcbPLU9Fjumz+SH08d0mpI\nb7i9yOKy/PSeOlyumJxOmMfN06tKeuw926NzCkopv+NyCROHxPGPz0tJjQnpVnmX9h6kNSdvIAeO\n1PdIcUmv6FAPz16V71TP7U0aFJRSfmmSHRR6YojH1+lZCZye1fOr7lo+cKq36PCRUsoveSsCd3aS\n2V/onYJSyi+lx4Xy7zOGMSP35Eyw7CsaFJRSfklEuO4sfaZXSzp8pJRSyqFBQSmllEODglJKKYcG\nBaWUUg4NCkoppRwaFJRSSjk0KCillHJoUFBKKeWQ9h5IfbISkQpgeze/PR6o7HCv/scf2+2PbQb/\nbLc/thm63u7BxpgOizJ954LC8RCRtcaY8X19HCeaP7bbH9sM/tluf2wz9F67dfhIKaWUQ4OCUkop\nh78Fhf/r6wPoI/7Ybn9sM/hnu/2xzdBL7farOQWllFLH5m93CkoppY5Bg4JSSimH3wQFEZkpIl+J\nyDYRua2vj6c3WQUm6wAABSlJREFUiMggEXlPRApE5EsRucHeHisib4vIVvvvmL4+1t4gIm4RWS8i\nr9uvM0Rktd3nL4iIp6+PsSeJSLSIvCQim0WkUEQm+kNfi8hN9u/3JhF5TkSC+2Nfi8gTIlIuIpt8\ntrXZv2J5yG7/5yIytruf6xdBQUTcwMPALCAHuFhEcvr2qHpFA/DvxpgcIB+4xm7nbcAKY0wWsMJ+\n3R/dABT6vL4feNAYMxTYByzuk6PqPb8D3jTGDAfysNrer/taRFKA64HxxpiRgBv4Pv2zr58EZrbY\n1l7/zgKy7D8/Bh7p7of6RVAAJgDbjDHFxpijwPPAvD4+ph5njCk1xqyz/30I6ySRgtXWJfZuS4D5\nfXOEvUdEUoFzgcft1wJMB16yd+lX7RaRKGAq8GcAY8xRY8x+/KCvsR4jHCIiAUAoUEo/7GtjzL+A\nvS02t9e/84CnjGUVEC0iA7vzuf4SFFKAb3xe77S39Vsikg6MAVYDicaYUvtLe4D++KTy3wK3Ak32\n6zhgvzGmwX7d3/o8A6gA/mIPmT0uImH08742xuwCHgB2YAWDA8Bn9O++9tVe//bYOc5fgoJfEZFw\n4GXgRmPMQd+vGWsNcr9ahywic4ByY8xnfX0sJ1AAMBZ4xBgzBqihxVBRP+3rGKyr4gwgGQij9RCL\nX+it/vWXoLALGOTzOtXe1u+ISCBWQHjWGLPU3lzmvZW0/y7vq+PrJZOBuSJSgjU0OB1rvD3aHmKA\n/tfnO4GdxpjV9uuXsIJEf+/rs4GvjTEVxph6YClW//fnvvbVXv/22DnOX4LCp0CWvULBgzUxtayP\nj6nH2ePofwYKjTG/8fnSMuBy+9+XA6+d6GPrTcaY240xqcaYdKy+fdcYcwnwHrDQ3q1ftdsYswf4\nRkSy7U1nAQX0877GGjbKF5FQ+/fd2+5+29cttNe/y4Af2KuQ8oEDPsNMXeI3Gc0iMhtr3NkNPGGM\nua+PD6nHicgU4EPgC74dW78Da17hRSANq+z4hcaYlhNY/YKInAHcYoyZIyKZWHcOscB64FJjTF1f\nHl9PEpHRWBPrHqAYuALrQq9f97WI3A1chLXabj3wI6zx837V1yLyHHAGVonsMuB/gFdpo3/tAPkH\nrKG0w8AVxpi13fpcfwkKSimlOuYvw0dKKaU6QYOCUkophwYFpZRSDg0KSimlHBoUlFJKOTQoKHUC\nicgZ3iquSp2MNCgopZRyaFBQqg0icqmIrBGRDSLyqP2shmoRedCu5b9CRBLsfUeLyCq7jv0rPjXu\nh4rIOyKyUUTWicgQ++3DfZ6D8KydeKTUSUGDglItiMgIrIzZycaY0UAjcAlW8bW1xphc4AOsDFOA\np4D/NMacgpVN7t3+LPCwMSYPmIRV1ROs6rU3Yj3bIxOrdo9SJ4WAjndRyu+cBYwDPrUv4kOwCo81\nAS/Y+zwDLLWfaxBtjPnA3r4E+JuIRAApxphXAIwxtQD2+60xxuy0X28A0oGPer9ZSnVMg4JSrQmw\nxBhze7ONIne22K+7NWJ8a/I0ov8P1UlEh4+Uam0FsFBEBoDzXNzBWP9fvJU4FwEfGWMOAPtE5HR7\n+2XAB/aT73aKyHz7PYJEJPSEtkKpbtArFKVaMMYUiMh/A8tFxAXUA9dgPchmgv21cqx5B7BKGP/J\nPul7q5WCFSAeFZF77Pe44AQ2Q6lu0SqpSnWSiFQbY8L7+jiU6k06fKSUUsqhdwpKKaUceqeglFLK\noUFBKaWUQ4OCUkophwYFpZRSDg0KSimlHP8Pf0jTswkE+8sAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6_BWcfEsE4Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c198bbab-b7bb-4b19-9ac5-278507d608d8"
      },
      "source": [
        "# mÃ©tricas de perda e acurÃ¡cia\n",
        "score = model.evaluate_generator(validation_set, 105)\n",
        "\n",
        "print (\"%s: %.2f%%\" % (model.metrics_names[0], score[0]*100))\n",
        "print (\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 103.40%\n",
            "acc: 52.43%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8RcvpB9sIO4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "272dfa60-89bd-4ba0-f11b-ce92b199c0bf"
      },
      "source": [
        "!pip install --upgrade --quiet PyDrive\n",
        "# para conectar com o Google Drive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |â                               | 10kB 21.0MB/s eta 0:00:01\r\u001b[K     |â                               | 20kB 7.1MB/s eta 0:00:01\r\u001b[K     |â                               | 30kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââ                              | 40kB 6.2MB/s eta 0:00:01\r\u001b[K     |ââ                              | 51kB 7.6MB/s eta 0:00:01\r\u001b[K     |ââ                              | 61kB 8.9MB/s eta 0:00:01\r\u001b[K     |âââ                             | 71kB 10.0MB/s eta 0:00:01\r\u001b[K     |âââ                             | 81kB 11.2MB/s eta 0:00:01\r\u001b[K     |âââ                             | 92kB 12.3MB/s eta 0:00:01\r\u001b[K     |ââââ                            | 102kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââ                            | 112kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââ                            | 122kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââ                           | 133kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââ                           | 143kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââ                           | 153kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââ                          | 163kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââ                          | 174kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââ                          | 184kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââ                         | 194kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââ                         | 204kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââ                         | 215kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââ                        | 225kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââ                        | 235kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââ                        | 245kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââ                       | 256kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââ                       | 266kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââ                       | 276kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââ                      | 286kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââ                      | 296kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââ                      | 307kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââ                     | 317kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââ                     | 327kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââ                     | 337kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââ                    | 348kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââ                    | 358kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââ                    | 368kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââ                   | 378kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââ                   | 389kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââ                   | 399kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââ                  | 409kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââ                  | 419kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââ                  | 430kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââ                 | 440kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââ                 | 450kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââ                 | 460kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââ                | 471kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââ                | 481kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââ                | 491kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââ               | 501kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââ               | 512kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââ               | 522kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââ              | 532kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââ              | 542kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââ              | 552kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââ             | 563kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââ             | 573kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââ             | 583kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââ            | 593kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââ            | 604kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââ            | 614kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââ           | 624kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââ           | 634kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââ           | 645kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââ          | 655kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââ          | 665kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââ          | 675kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââ         | 686kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââ         | 696kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââ         | 706kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââ        | 716kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââ        | 727kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââ        | 737kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââââ       | 747kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââââ       | 757kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââââ       | 768kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââââ      | 778kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââââ      | 788kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââââ      | 798kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââââââ     | 808kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââââââ     | 819kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââââââ     | 829kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââââââ    | 839kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââââââ    | 849kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââââââ    | 860kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââââââââ   | 870kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââââââââ   | 880kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââââââââ   | 890kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââââââââ  | 901kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââââââââ  | 911kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââââââââ  | 921kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââââââââââ | 931kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââââââââââ | 942kB 9.9MB/s eta 0:00:01\r\u001b[K     |âââââââââââââââââââââââââââââââ | 952kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââââââââââ| 962kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââââââââââ| 972kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââââââââââ| 983kB 9.9MB/s eta 0:00:01\r\u001b[K     |ââââââââââââââââââââââââââââââââ| 993kB 9.9MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBvCnQOQsKhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Salvando o modelo no drive\n",
        "\n",
        "model.save(\"model_inceptionresnetv2.h5\")\n",
        "uploaded = drive.CreateFile({'title': 'model_inceptionresnetv2.h5'})\n",
        "uploaded.SetContentFile('model_inceptionresnetv2.h5')\n",
        "uploaded.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHaJuIQzwCM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcTUIJo8wQbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importando imagens de teste do drive\n",
        "\n",
        "link = 'https://drive.google.com/open?id=1sbjcK__NABa7gfsPOt7JM8jAaXCLCfKW'\n",
        "fluff, id = link.split('=')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('teste1_cytHigh-grade Squamous Intraepithelial Lesion - 14659.jpg')\n",
        "\n",
        "link = 'https://drive.google.com/open?id=1vDBjgozlaLg0tcGQ50b9wpOBz_NYyx8o'\n",
        "fluff, id = link.split('=')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('teste2_cyt14721.jpg')\n",
        "\n",
        "link = 'https://drive.google.com/open?id=14mCco19UM0k83Irdz3xk2lQaOs7a1YuK'\n",
        "fluff, id = link.split('=')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('teste3_cytoCandida - 7557.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELjE-aJ6wVXS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68791e7b-8eb1-4639-85b1-1640788c4c8b"
      },
      "source": [
        "# Testando o modelo\n",
        "from keras.preprocessing import image\n",
        "\n",
        "test_image = image.load_img('teste3_cytoCandida - 7557.jpg', target_size = (299, 299))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = model.predict(test_image)\n",
        "\n",
        "if result[0][0] == 0:\n",
        "    diagnostico = 'Carcinoma'\n",
        "elif result[0][0] == 1:\n",
        "    diagnostico = 'Normal'\n",
        "else:\n",
        "    diagnostico = 'Outros problemas'\n",
        "    \n",
        "print ('DiagnÃ³stico:', diagnostico)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DiagnÃ³stico: Normal\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}