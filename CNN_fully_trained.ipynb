{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN - fully trained.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lcroffi/CNN/blob/master/CNN_fully_trained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZAwj1O_-nI4",
        "colab_type": "code",
        "outputId": "da2a9519-c09b-4458-9fea-25bcc8e10772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mchHUe-f-1Gw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_width, img_height = 200, 200 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WLiQbb0_urt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Baixar as imagens do exame de citologia cervical\n",
        "!wget -cq https://citologia-cervical.s3-sa-east-1.amazonaws.com/citologia.zip\n",
        "!unzip -qq citologia.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZamB4O2FrGr",
        "colab_type": "code",
        "outputId": "c9609578-bcd7-4ecb-f954-f438be3162a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "from keras.callbacks import *\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "filepath=\"/content/drive/My Drive/Colab Notebooks/log/training:{epoch:03d}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWcGRef8_HIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(p, input_shape=(32, 32, 3)):\n",
        "    # Initialising the CNN\n",
        "    model = Sequential()\n",
        "    # Convolution + Pooling Layer \n",
        "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    # Convolution + Pooling Layer \n",
        "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    # Convolution + Pooling Layer \n",
        "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    # Convolution + Pooling Layer \n",
        "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    \n",
        "    # Flattening\n",
        "    model.add(Flatten())\n",
        "    # Fully connection\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(p))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(p/2))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    \n",
        "    # Compiling the CNN\n",
        "    optimizer = Adam(lr=1e-4)\n",
        "    metrics=['accuracy']\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=metrics)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVZ6ZJgP_Lvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_training(bs=32, epochs=10):\n",
        "    \n",
        "    train_datagen = ImageDataGenerator(rescale = 1./255, \n",
        "                                       shear_range = 0.2, \n",
        "                                       zoom_range = 0.2, \n",
        "                                       horizontal_flip = True)\n",
        "    test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        " \n",
        "    training_set = train_datagen.flow_from_directory('train',\n",
        "                                                 target_size = (img_width, img_height),\n",
        "                                                 batch_size = bs,\n",
        "                                                 class_mode = 'categorical')\n",
        "                                                 \n",
        "    test_set = test_datagen.flow_from_directory('valid',\n",
        "                                            target_size = (img_width, img_height),\n",
        "                                            batch_size = bs,\n",
        "                                            class_mode = 'categorical')\n",
        "                                            \n",
        "    model = create_model(p=0.6, input_shape=(img_width, img_height, 3))\n",
        "    history = model.fit_generator(training_set,\n",
        "                         steps_per_epoch=8000/bs,\n",
        "                         epochs = epochs,\n",
        "                         validation_data = test_set,\n",
        "                         validation_steps = 2000/bs,\n",
        "                         callbacks=callbacks_list)\n",
        "    \n",
        "    model.save(\"model.h5\")\n",
        "    \n",
        "    score = model.evaluate_generator(test_set, 105)\n",
        "\n",
        "    print (\"%s: %.2f%%\" % (model.metrics_names[0], score[0]*100))\n",
        "    print (\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "    \n",
        "    return history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td2zo4UNAtfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def history (hist):\n",
        "  \n",
        "    # listar todos os dados no history\n",
        "    print(hist.history.keys())\n",
        "    # Gráfico de treino - acurácia\n",
        "    plt.plot(hist.history['acc'])\n",
        "    plt.plot(hist.history['val_acc'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "    # Gráfico de treino - perda\n",
        "    plt.plot(hist.history['loss'])\n",
        "    plt.plot(hist.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq1VyYn4_PL9",
        "colab_type": "code",
        "outputId": "9d6c649c-b25d-40cb-ea38-edd582e1d19c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def main():\n",
        "    hist = run_training(bs=32, epochs=100)\n",
        "    history(hist)\n",
        " \n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 423 images belonging to 3 classes.\n",
            "Found 105 images belonging to 3 classes.\n",
            "Epoch 1/100\n",
            "250/250 [==============================] - 105s 419ms/step - loss: 1.0719 - acc: 0.3889 - val_loss: 1.0356 - val_acc: 0.3812\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.59066\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 99s 396ms/step - loss: 1.0397 - acc: 0.4186 - val_loss: 0.9896 - val_acc: 0.4848\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.59066\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 99s 396ms/step - loss: 1.0042 - acc: 0.4599 - val_loss: 0.9785 - val_acc: 0.5746\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.59066\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 99s 397ms/step - loss: 0.9442 - acc: 0.5349 - val_loss: 1.1009 - val_acc: 0.4945\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.59066\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 99s 397ms/step - loss: 0.8857 - acc: 0.5807 - val_loss: 1.0405 - val_acc: 0.5326\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.59066\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 99s 397ms/step - loss: 0.8217 - acc: 0.6272 - val_loss: 1.0969 - val_acc: 0.5182\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.59066\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 99s 395ms/step - loss: 0.7472 - acc: 0.6729 - val_loss: 1.0917 - val_acc: 0.5042\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.59066\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 99s 397ms/step - loss: 0.6840 - acc: 0.6968 - val_loss: 1.1529 - val_acc: 0.5419\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.59066\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 99s 396ms/step - loss: 0.6201 - acc: 0.7331 - val_loss: 1.2086 - val_acc: 0.5242\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.59066\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 99s 396ms/step - loss: 0.5692 - acc: 0.7581 - val_loss: 1.1995 - val_acc: 0.5716\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.59066\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 99s 397ms/step - loss: 0.5078 - acc: 0.7840 - val_loss: 1.1083 - val_acc: 0.5419\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.59066\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 99s 396ms/step - loss: 0.4718 - acc: 0.7995 - val_loss: 1.4639 - val_acc: 0.5625\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.59066\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 99s 397ms/step - loss: 0.4098 - acc: 0.8265 - val_loss: 1.5225 - val_acc: 0.5625\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.59066\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 99s 396ms/step - loss: 0.3931 - acc: 0.8404 - val_loss: 1.4017 - val_acc: 0.5874\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.59066\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 99s 397ms/step - loss: 0.3346 - acc: 0.8654 - val_loss: 1.6080 - val_acc: 0.5898\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.59066\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 99s 396ms/step - loss: 0.2944 - acc: 0.8810 - val_loss: 1.7893 - val_acc: 0.5710\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.59066\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 100s 399ms/step - loss: 0.2803 - acc: 0.8859 - val_loss: 2.2773 - val_acc: 0.5338\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.59066\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 99s 398ms/step - loss: 0.2756 - acc: 0.8882 - val_loss: 2.2453 - val_acc: 0.5431\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.59066\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 99s 398ms/step - loss: 0.2445 - acc: 0.8986 - val_loss: 2.1547 - val_acc: 0.5413\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.59066\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 100s 398ms/step - loss: 0.2305 - acc: 0.9038 - val_loss: 2.2711 - val_acc: 0.5431\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.59066\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 99s 397ms/step - loss: 0.2088 - acc: 0.9188 - val_loss: 2.0740 - val_acc: 0.5919\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.59066 to 0.59186, saving model to /content/drive/My Drive/Colab Notebooks/training:021-val_acc:0.592.hdf5\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 98s 394ms/step - loss: 0.1939 - acc: 0.9197 - val_loss: 2.3204 - val_acc: 0.5801\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.59186\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 100s 399ms/step - loss: 0.1867 - acc: 0.9238 - val_loss: 2.4503 - val_acc: 0.5904\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.59186\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 100s 399ms/step - loss: 0.1933 - acc: 0.9202 - val_loss: 2.5307 - val_acc: 0.5498\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.59186\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 99s 397ms/step - loss: 0.1667 - acc: 0.9328 - val_loss: 2.0402 - val_acc: 0.5817\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.59186\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 99s 398ms/step - loss: 0.1820 - acc: 0.9231 - val_loss: 2.5374 - val_acc: 0.6104\n",
            "\n",
            "Epoch 00026: val_acc improved from 0.59186 to 0.61044, saving model to /content/drive/My Drive/Colab Notebooks/training:026-val_acc:0.610.hdf5\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 100s 399ms/step - loss: 0.1644 - acc: 0.9329 - val_loss: 2.2828 - val_acc: 0.5892\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.61044\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 99s 397ms/step - loss: 0.1514 - acc: 0.9386 - val_loss: 2.3733 - val_acc: 0.5510\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.61044\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 99s 397ms/step - loss: 0.1506 - acc: 0.9365 - val_loss: 2.5632 - val_acc: 0.5996\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.61044\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 99s 398ms/step - loss: 0.1381 - acc: 0.9437 - val_loss: 2.5688 - val_acc: 0.5831\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.61044\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 99s 397ms/step - loss: 0.1287 - acc: 0.9474 - val_loss: 2.9066 - val_acc: 0.5825\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.61044\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 99s 397ms/step - loss: 0.1419 - acc: 0.9434 - val_loss: 2.4104 - val_acc: 0.5898\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.61044\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 100s 398ms/step - loss: 0.1221 - acc: 0.9504 - val_loss: 2.6102 - val_acc: 0.6098\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.61044\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 100s 398ms/step - loss: 0.1254 - acc: 0.9491 - val_loss: 2.7193 - val_acc: 0.6007\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.61044\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 99s 396ms/step - loss: 0.1230 - acc: 0.9505 - val_loss: 2.6963 - val_acc: 0.6104\n",
            "\n",
            "Epoch 00035: val_acc improved from 0.61044 to 0.61044, saving model to /content/drive/My Drive/Colab Notebooks/training:035-val_acc:0.610.hdf5\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 100s 398ms/step - loss: 0.1118 - acc: 0.9566 - val_loss: 3.2362 - val_acc: 0.5413\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.61044\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 100s 398ms/step - loss: 0.1170 - acc: 0.9508 - val_loss: 3.0066 - val_acc: 0.5811\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.61044\n",
            "Epoch 38/100\n",
            "247/250 [============================>.] - ETA: 1s - loss: 0.1489 - acc: 0.9434"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keLWMSRVyQD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpVfoRB5zZvV",
        "colab_type": "code",
        "outputId": "71184d0a-46d3-4e9a-ede9-1c1b346e5ce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!pip install --upgrade --quiet PyDrive\n",
        "# para conectar com o Google Drive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 15.6MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 4.8MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 6.8MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 4.2MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 6.1MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 6.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 7.7MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 8.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 6.7MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 6.7MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 6.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 6.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 6.7MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpfjPVG0zfM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importando imagens de teste do drive\n",
        "\n",
        "link = 'https://drive.google.com/open?id=1sbjcK__NABa7gfsPOt7JM8jAaXCLCfKW'\n",
        "fluff, id = link.split('=')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('teste1_cytHigh-grade Squamous Intraepithelial Lesion - 14659.jpg')\n",
        "\n",
        "link = 'https://drive.google.com/open?id=1vDBjgozlaLg0tcGQ50b9wpOBz_NYyx8o'\n",
        "fluff, id = link.split('=')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('teste2_cyt14721.jpg')\n",
        "\n",
        "link = 'https://drive.google.com/open?id=14mCco19UM0k83Irdz3xk2lQaOs7a1YuK'\n",
        "fluff, id = link.split('=')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('teste3_cytoCandida - 7557.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZgTjcxLzjB1",
        "colab_type": "code",
        "outputId": "a41a76f3-be97-454b-dd1f-c6d29c0e10e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Testando o modelo\n",
        "from keras.preprocessing import image\n",
        "\n",
        "test_image = image.load_img('teste3_cytoCandida - 7557.jpg', target_size = (200, 200))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = model.predict(test_image)\n",
        "\n",
        "if result[0][0] == 0:\n",
        "    diagnostico = 'Carcinoma'\n",
        "elif result[0][0] == 1:\n",
        "    diagnostico = 'Normal'\n",
        "else:\n",
        "    diagnostico = 'Outros problemas'\n",
        "    \n",
        "print ('Diagnóstico:', diagnostico)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Diagnóstico: Carcinoma\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZad45XS-xTA",
        "colab_type": "code",
        "outputId": "9350aa2c-86d7-4ca6-92ee-1983c175236c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Best Weights 14/07\n",
        "\n",
        "input_shape = (img_width, img_height, 3)\n",
        "p = 0.6\n",
        "bs = 32\n",
        "# Initialising the CNN\n",
        "model = Sequential()\n",
        "# Convolution + Pooling Layer \n",
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# Convolution + Pooling Layer \n",
        "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# Convolution + Pooling Layer \n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# Convolution + Pooling Layer \n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    \n",
        "# Flattening\n",
        "model.add(Flatten())\n",
        "# Fully connection\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(p))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(p/2))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.load_weights('/content/drive/My Drive/Colab Notebooks/log/training:057-val_acc:0.656.hdf5') # Melhor treino do algoritmo\n",
        "\n",
        "# Compiling the CNN\n",
        "optimizer = Adam(lr=1e-4)\n",
        "metrics=['accuracy']\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=metrics)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('valid',\n",
        "                                            target_size = (img_width, img_height),\n",
        "                                            batch_size = bs,\n",
        "                                            class_mode = 'categorical')\n",
        "\n",
        "score = model.evaluate_generator(test_set, 105)\n",
        "\n",
        "print (\"%s: %.2f%%\" % (model.metrics_names[0], score[0]*100))\n",
        "print (\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 105 images belonging to 3 classes.\n",
            "loss: 280.88%\n",
            "acc: 65.71%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}